---
params:
  projectdir: !expr paste0("/mnt/", Sys.getenv("STUDY_ID_DIR"))
  project_name: !expr Sys.getenv("STUDY_ID_DIR")
  clust_method: "spearman" # For clustering
  tree_height_cutoff: 0.1 # For clustering
  dendro_color_by: "Dose" # Specify how you would like to color the dendrograms
  nmr_threshold: 1000000 # 10% of 1M reads for TempOSeq = 100,000; 10% of 10M reads for RNA-Seq = 1,000,000.
  align_threshold: 0.7 # 50% alignment rate for Targeted-RNAseq Experiments, 70% for RNA-seq
  gini_cutoff: 0.95 # If dataset has no replicates, set gini to 1... DEFAULT TO (0.99)
  q30_cutoff: 0.7 # Discard samples if % of Q scores â‰¥ 30 was less than 70% by default
  forward_reverse_q30_diff_cutoff: 0.25 # Discard samples if the difference in the q30_percentage is greater than 0.25 by default. This is not necessary for single reads.
  PCA_cutoff: 0.2 # Default is 20%. Sample not clustering with their dose replicates (>20% variance) are removed
  sampledata_sep: "\t" # Comma for TempO-Seq, Maybe tabs for RNASeq, customize!
  groups: ["Compound", "Dose"] # These should be "interesting" groups for your analysis. Group together for exploring covariation.
  batch_var: NULL # "batch"
  dose: "Dose" # If there is a dose in the experiment, e.g., "Dose"; otherwise use NULL
  treatment_var: "Compound"
  Platform: "RNA-Seq" # TempO-Seq Or RNA-Seq
  technical_control: "technical_control" # Column names for metadata, if applicable
  reference_rna: "reference_rna" # Column names for metadata, if applicable
  solvent_control: "solvent_control" # Column names for metadata, if applicable
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: hide
    theme: spacelab # flatly spacelab sandstone cerulean
    code_download: true
bibliography: "`r file.path('/mnt', Sys.getenv('STUDY_ID_DIR'), 'Rmd', 'references.bib')`"
title: "`r paste('Study-wide sample quality control:', gsub(pattern = '_', replacement = ' ', x = Sys.getenv('STUDY_ID_DIR')))`"
author: "Jory Curry"
---

# `r paste('Study-wide sample quality control:', gsub(pattern = '_', replacement = ' ', x = Sys.getenv('STUDY_ID_DIR')))`

***

This report is generated for the project `r params$project_name` located at `r params$projectdir`.

Modified from code provided by Andrew Williams (Health Canada) and recommendations from Joshua Harrill (US EPA). See [References].  

This should be run prior to DEG/BMD analysis to remove any suspect samples from across the entire study.  

The metadata you use should have the following columns with T or F listed for each sample:  

* `technical_control`  
* `reference_rna`  
* `solvent_control`  

***

```{r load_libraries, message = F, warnings = F, echo = F}


############################################################################
# Libraries
############################################################################

#### Record start time
startTime <- Sys.time()

#Making your own conda environment with all the necessary packages...
#conda create --name my_r_pkgs --clone r_pkgs
#conda install -c conda-forge r-packagename OR
#conda install -c bioconda bioconductor-packagename
#NOTE: use the updated_my_r_pkgs conda env
#personal_lib_path <- "~/R_libs"

library(edgeR)                      #In default r_pkgs conda env and my_r_pkgs conda env
library(ggplot2)                    #In default r_pkgs conda env and my_r_pkgs conda env
library(data.table)                 #In default r_pkgs conda env and my_r_pkgs conda env
library(cluster)                    #In default r_pkgs conda env and my_r_pkgs conda env
#library(extrafont)                 #NEW - fonts...
#library(showtextdb)                #NEW - need fonts to render reports: In my_r_pkgs conda env
#library(showtext)                  #NEW - use fonts in reports: In my_r_pkgs conda env
library(Cairo)                      # In updated_my_r_pkgs conda env
library(jsonlite)                   # In updated_my_r_pkgs conda env #NEW!
library(sfsmisc)                    #In my_r_pkgs conda env
library(fields)                     #In my_r_pkgs conda env
library(heatmap3)                   #In my_r_pkgs conda env
library(DESeq2)                     #In default r_pkgs conda env and my_r_pkgs conda env
library(tidyverse)                  #In my_r_pkgs conda env
library(foreach)                    #In my_r_pkgs conda env
library(doParallel)                 #In my_r_pkgs conda env
library(UpSetR)                     #In my_r_pkgs conda env
library(GGally)                     #In my_r_pkgs conda env
library(pheatmap)                   #In default r_pkgs conda env and my_r_pkgs conda env
#library(ComplexHeatmap, lib.loc = "~/R_libs")#All conda versions are incompatible with other packages
library(kableExtra)                 #In my_r_pkgs conda env
library(dendextend)                 #In my_r_pkgs conda env
library(dendsort)                   #In my_r_pkgs conda env
library(rrcov)                      #In my_r_pkgs conda env
library(cellWise, lib.loc = "~/R_libs")#In my_r_pkgs conda env - I had to manually download an archived version compatible with R 3.6.3
library(vtree)                      #In my_r_pkgs conda env
#library(here)                       #In my_r_pkgs conda env
library(devtools)                   # In updated_my_r_pkgs conda env #NEW!
```


```{r params, include = FALSE, echo = FALSE, message = FALSE}
projectdir <- params$projectdir
chemical_name <- sub("^.*Study_id_\\d+_([^_]+)_\\d+(\\.\\d+)?_day_exposure$", "\\1", projectdir)
clust_method <- params$clust_method
tree_height_cutoff <- params$tree_height_cutoff
dendro_color_by <- params$dendro_color_by
nmr_threshold <- params$nmr_threshold
align_threshold <- params$align_threshold
gini_cutoff <- params$gini_cutoff
q30_cutoff <- params$q30_cutoff
forward_reverse_q30_diff_cutoff <-
  params$forward_reverse_q30_diff_cutoff
PCA_cutoff <- params$PCA_cutoff
sampledata_sep <- params$sampledata_sep
groups <- params$groups
#groups[[2]]: c("I7_Index_ID","I5_Index_ID")
#groups[[3]]: c("Row","Column")
#groups[[4]]: c("Batch")
groups <-
  unname(groups) # Include b/c of how things are addressed throughout.
batch_var <- params$batch_var
dose <- params$dose
treatment_var <- params$treatment_var
Platform <- params$Platform
# Column names for metadata, if applicable
technical_control <- params$technical_control
reference_rna <- params$reference_rna
solvent_control <- params$solvent_control
```

```{r paths}
############################################################################
# File paths in project directory
############################################################################
projectdir <- projectdir
paths <- list()
paths$root <- "/mnt"
paths$data <- projectdir
paths$output <- paste0(paths$data, "/output")
paths$processed <-
  paste0(paths$output, "/Trimmed_reads/RSEM/") #This directory should be contain the count table output by R-ODAF_1_sequencing_DataPreprocess...
paths$metadata <-
  paths$root #Back to GSE Accession ID parent directory that contains the metadata file, e.g., normalizePath(file.path(paths$root, ".."))
# Need to update this path... temporary for testing purposes
paths$reports <- paste0(paths$data, "/reports")
if (!dir.exists(paths$reports)) {
  print("Creating Report dir")
  dir.create(paths$reports)
} else {
  print("Report dir exists.")
}

knitr::opts_knit$set(root.dir = paths$root)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
options(browser = "false") # Set browser option to a dummy value because I am in an HPC environment that does not have a browser

# Function to safely include graphics
include_safe_graphics <- function(file_path) {
  absolute_path <- normalizePath(file_path, mustWork = FALSE)
  if (file.exists(absolute_path)) {
    knitr::include_graphics(absolute_path, error = FALSE)
  } else {
    message(paste("File does not exist:", absolute_path))
  }
}
```

```{r load_files, message = F, results = "hide"}
############################################################################
# FILES TO LOAD
############################################################################

# A. File with read counts
if (Platform == "TempO-Seq") {
  ########################################################################
  SampleDataFile <-
    normalizePath(file.path(paths$output, "count_table.csv"))
  MappedUnmapped <-
    normalizePath(file.path(paths$output, "mapped_unmapped.csv"))
  sampledata_sep <- ","
  collapse_reps <- function(filepath) {
    df <- read.table(file = filepath,
                     sep = ",",
                     header = T)
    names(df) = gsub(pattern = "_trimmed",
                     replacement = "",
                     x = names(df))
    df <- df %>% pivot_longer(
      cols = -c("X"),
      names_to = c('.value', 'flowcell'),
      names_pattern = '(.*)_(.*)'
    )
    df[is.na(df)] <- 0
    sampleDataTable <-
      data.table(df %>% dplyr::select(-c(flowcell)))
    results <- sampleDataTable[, lapply(.SD, sum), by = "X"]
    return(results)
  }
  sampleData <- collapse_reps(SampleDataFile)
  MappedUnmapped <- collapse_reps(MappedUnmapped)
  write.table(
    sampleData,
    file = normalizePath(file.path(paths$processed, "count_table.csv")),
    sep = ",",
    quote = F,
    row.names = F
  )
  write.table(
    MappedUnmapped,
    file = normalizePath(file.path(
      paths$processed, "mapped_unmapped.csv"
    )),
    sep = ",",
    quote = F,
    row.names = F
  )
  sampleData <-
    read.table(
      normalizePath(file.path(paths$processed, "count_table.csv")),
      sep = sampledata_sep,
      stringsAsFactors = FALSE,
      header = TRUE,
      quote = "\"",
      row.names = 1,
      check.names = FALSE
    )
  mu <-
    read.table(
      normalizePath(file.path(
        paths$processed, "mapped_unmapped.csv"
      )),
      sep = ",",
      header = T,
      row.names = 1,
      stringsAsFactors = F,
      check.names = F
    )
  mu <- as.data.frame(t(mu))
  mu$pct_mapped <- mu$mapped / (mu$mapped + mu$unmapped)
  ########################################################################
} else {
  #Any other sequencing technology
  SampleDataFile <-
    normalizePath(file.path(paths$processed, "genes.data.tsv")) #projectdir/output/Trimmed_reads/RSEM/genes.data.tsv
  sampleData <- read.table(
    SampleDataFile,
    sep = sampledata_sep,
    #Typically \t
    stringsAsFactors = FALSE,
    header = TRUE,
    quote = "\"",
    row.names = 1,
    #first col is rownames
    check.names = FALSE
  )
  mu <- NULL
}

# B. Tab delimited sample information file with at least 2 columns:
#    1. sample names identical to the column names of sampleData
#    2. compound/group/whatever (needs to identify to which experimental group the sample belongs) #We will have compound and Dose in otu SRATables
SampleKeyFile <-
  normalizePath(file.path(paths$metadata, "SraRunTable.csv")) #Up one from the Study_id directory in root corresponding to the ACCESSION ID

DESeqDesign <- read.delim(
  SampleKeyFile,
  stringsAsFactors = FALSE,
  sep = ",",
  #SRATables are comma-separated
  header = TRUE,
  quote = "\"",
  row.names = NULL
)

# Function to check if all colnames of sampleData end with "_1" and remove the suffix
clean_sample_names <- function(sampleData, DESeqDesign) {
  # Check if all column names end with "_1"
  if (all(grepl("_1$", colnames(sampleData)))) {
    # Remove "_1" from the column names
    colnames(sampleData) <- sub("_1$", "", colnames(sampleData))
    
    # Verify that the names now match between sampleData and DESeqDesign$Run
    if (all(colnames(sampleData) %in% DESeqDesign$Run)) {
      message("Sample names successfully cleaned and matched with metadata.")
    } else {
      warning("Sample names were cleaned, but do not match the metadata.")
    }
  } else {
    message("Sample names do not require cleaning. No changes made.")
  }
  
  return(sampleData)
}

# Apply the function to clean sample names
sampleData <- clean_sample_names(sampleData, DESeqDesign)

temp_samplenames <- names(sampleData)
DESeqDesign$original_names <-
  DESeqDesign[, 1] #This assumes the Run name is in the first column
DESeqDesign <-
  DESeqDesign[DESeqDesign$original_names %in% temp_samplenames,] #Filtering the DESeqDesign to just be the samples in this dataset... useful for metadata containing data from multiple experiments/study ids
DESeqDesign <- 
   DESeqDesign[DESeqDesign$Compound == chemical_name, ] #Filtering the DESeqDesign by chemical name present in the project directory name


############################################################################
# Arrange tables by sample names
############################################################################

sampleData <-
  sampleData %>% dplyr::relocate(colnames(sampleData) %>% sort())
ncol(sampleData)

#design
d <- DESeqDesign
d <- d %>% dplyr::arrange(original_names)
nrow(d)

############################################################################
#Checking row and column orderings
############################################################################
all(names(sampleData) %in% d$original_names)
all(names(sampleData) == d$original_names)
d <- d[d$original_names %in% names(sampleData), ]
DESeqDesign <- d
all(names(sampleData) == d$original_names)
```

# Sample Filtering {.tabset}

## Q30 score (Phred score)

Base Q-scores of 30 or above have a base calling accuracy of 99.9%+ A Q-score of 20 corresponds to just 99% accuracy. Therefore samples with an average Q-score of 30 are of excellent quality. The R-ODAF default cutoff threshold for removing samples with poor quality is 70%. This QC report uses a q30 cutoff of `r q30_cutoff*100`%. 

For paired-end data, if the difference between the sample's Q30 percentage from the forward and reverse reads are more than 25% by default, the sample is flagged for removal. This report uses a forward-reverse Q30 difference cutoff of `r forward_reverse_q30_diff_cutoff*100`%.

```{r q30_filtering, eval=TRUE, warning=FALSE, fig.height=8, fig.width=10, out.width='100%', out.height='100%'}


#NOTE: Might need change for TempO-Seq

############################################################################
# Flagging samples based on their Quality/Phred scores!
############################################################################
#params$q30_cutoff
#params$forward_reverse_q30_diff_cutoff

parse_fastp_json <- function(json_dir, q30_params) {
  # Check if directory exists and contains JSON files
  if (!dir.exists(json_dir) ||
      length(list.files(json_dir, pattern = "\\.json$", full.names = TRUE)) == 0) {
    print(
      "Q30 scores are not available in JSON files to analyze in the fastpQC output directory, please review."
    )
    return(NULL)
  }
  # Helper function to calculate Q30 percentages
  calculate_q30_percentage <- function(data) {
    list(
      before_filtering = data$summary$before_filtering$q30_bases / data$summary$before_filtering$total_bases * 100,
      after_filtering = data$summary$after_filtering$q30_bases / data$summary$after_filtering$total_bases * 100
    )
  }
  
  # Initialize an empty data frame
  results <- data.frame(
    sample_name = character(),
    q30_before = numeric(),
    q30_after = numeric(),
    read1_q30_after = numeric(),
    read2_q30_after = numeric(),
    passes_q30_threshold = logical(),
    diff_r1_r2_before = numeric(),
    diff_r1_r2_after = numeric(),
    passes_diff_threshold = logical(),
    is_paired_end = logical(),
    stringsAsFactors = FALSE
  )
  
  # List all JSON files in the directory
  json_files <-
    list.files(json_dir, pattern = "\\.json$", full.names = TRUE)
  
  for (file in json_files) {
    # Read the JSON file
    data <- jsonlite::fromJSON(file)
    
    # Extract the sample name
    sample_name <-
      gsub("_fastp\\.json|PE_fastp\\.json", "", basename(file))
    
    # Calculate Q30 percentages
    q30_percentages <- calculate_q30_percentage(data)
    
    if (grepl("PE_fastp\\.json$", file)) {
      # Paired-end data
      read1_q30_after <-
        data$read1_after_filtering$q30_bases / data$read1_after_filtering$total_bases * 100
      read2_q30_after <-
        data$read2_after_filtering$q30_bases / data$read2_after_filtering$total_bases * 100
      
      diff_before <-
        abs(
          data$read1_before_filtering$q30_bases / data$read1_before_filtering$total_bases * 100 -
            data$read2_before_filtering$q30_bases / data$read2_before_filtering$total_bases * 100
        )
      diff_after <- abs(read1_q30_after - read2_q30_after)
      
      passes_diff_threshold <-
        diff_before <= q30_params$forward_reverse_q30_diff_cutoff * 100 &&
        diff_after <= q30_params$forward_reverse_q30_diff_cutoff * 100
      passes_q30_threshold <-
        (read1_q30_after >= q30_params$q30_cutoff * 100) &
        (read2_q30_after >= q30_params$q30_cutoff * 100)
      
      results <- results %>%
        add_row(
          sample_name = sample_name,
          q30_before = q30_percentages$before_filtering,
          q30_after = q30_percentages$after_filtering,
          read1_q30_after = read1_q30_after,
          read2_q30_after = read2_q30_after,
          diff_r1_r2_before = diff_before,
          diff_r1_r2_after = diff_after,
          passes_q30_threshold = passes_q30_threshold,
          passes_diff_threshold = passes_diff_threshold,
          is_paired_end = TRUE
        )
    } else {
      # Single-end data
      passes_diff_threshold <- TRUE
      passes_q30_threshold <-
        q30_percentages$after_filtering >= q30_params$q30_cutoff * 100
      
      results <- results %>%
        add_row(
          sample_name = sample_name,
          q30_before = q30_percentages$before_filtering,
          q30_after = q30_percentages$after_filtering,
          read1_q30_after = NA,
          read2_q30_after = NA,
          diff_r1_r2_before = NA,
          diff_r1_r2_after = NA,
          passes_q30_threshold = passes_q30_threshold,
          passes_diff_threshold = passes_diff_threshold,
          is_paired_end = FALSE
        )
    }
  }
  
  return(results)
}

plot_q30_scores <- function(results) {
  if (is.null(results) || nrow(results) == 0) {
    print("No Q30 scores data available to plot.")
    return()
  }
  # Separate single-end and paired-end data
  single_end_data <- results %>% filter(!is_paired_end)
  paired_end_data <- results %>% filter(is_paired_end)
  
  # Plot single-end data
  if (nrow(single_end_data) > 0) {
    p_single <-
      ggplot(
        single_end_data,
        aes(x = sample_name, y = q30_after, fill = "Percentage of Q30 or higher bases")
      ) +
      geom_bar(stat = "identity") +
      geom_hline(yintercept = 70,
                 linetype = "dashed",
                 color = "red") +
      scale_y_continuous(limits = c(0, 100), expand = c(0, 0)) +
      labs(x = "Sample Name", y = "Q30 Percentage", fill = "") +
      theme_minimal() +
      theme(
        legend.position = "top",
        axis.text.x = element_text(
          angle = 90,
          hjust = 1,
          vjust = 1
        )
      ) +
      geom_text(
        aes(
          x = sample_name,
          y = q30_after / 2,
          label = paste(round(q30_after, 2))
        ),
        vjust = 0.5,
        angle = 90
      )
    print(p_single)
    ggsave(p_single,
           file = paste0(paths$output, "/Q30_plot_single_end_reads.pdf"))
    #knitr::include_graphics(paste0(paths$output, "/Q30_plot_single_end_reads.pdf"))
  }
  
  # Plot paired-end data
  if (nrow(paired_end_data) > 0) {
    paired_end_data_long <- paired_end_data %>%
      select(sample_name,
             read1_q30_after,
             read2_q30_after,
             diff_r1_r2_after) %>%
      pivot_longer(
        cols = c("read1_q30_after", "read2_q30_after"),
        names_to = "read",
        values_to = "q30_after"
      ) %>%
      mutate(read = stringr::str_split(read, pattern = "_q30_", simplify = TRUE)[, 1])
    
    p_paired <-
      ggplot(
        paired_end_data_long,
        aes(
          x = interaction(read, sample_name),
          y = q30_after,
          fill = "Percentage of Q30 or higher bases"
        )
      ) +
      geom_bar(stat = "identity", position = "dodge") +
      geom_hline(yintercept = 70,
                 linetype = "dashed",
                 color = "red") +
      scale_y_continuous(limits = c(0, 100), expand = c(0, 0)) +
      labs(x = "Sample Name (Read)", y = "Q30 Percentage", fill = "") +
      theme_minimal() +
      theme(
        legend.position = "top",
        axis.text.x = element_text(
          angle = 90,
          hjust = 1,
          vjust = 1
        )
      ) +
      geom_text(
        aes(y = q30_after / 2, label = paste(round(q30_after, 2))),
        vjust = 0.5,
        angle = 90,
        position = position_dodge(width = 0.9)
      ) +
      geom_text(
        aes(
          x = interaction(read, sample_name),
          y = 90,
          label = paste0("Diff: ", round(diff_r1_r2_after, 2))
        ),
        position = position_dodge2(width = 0.9, padding = 0.5),
        angle = 90
      )
    
    print(p_paired)
    ggsave(p_paired,
           file = paste0(paths$output, "/Q30_plot_paired_end_reads.pdf"))
    #knitr::include_graphics(paste0(paths$output, "/Q30_plot_paired_end_reads.pdf"))
  }
}

#params <- list(q30_cutoff = 0.7, forward_reverse_q30_diff_cutoff = 0.25)
q30_params <-
  list(q30_cutoff = q30_cutoff,
       forward_reverse_q30_diff_cutoff = forward_reverse_q30_diff_cutoff)
json_dir <- paste0(paths$output, "/Trimmed_reads/fastpQCoutput/")
results_df <- parse_fastp_json(json_dir, q30_params)
if (!is.null(results_df)) {
  #print(results_df)
  knitr::kable(results_df,
               caption = "Q30 Results") %>%
    kable_styling(
      bootstrap_options = "striped",
      full_width = F,
      position = "left"
    ) %>%
    kableExtra::scroll_box(width = "100%", height = "480px")
  plot_q30_scores(results_df)
}

```

## Read mapping percentage

A read mapping percentage cutoff of `r align_threshold*100`% is used to separate outliers.

```{r Percent_Mapping_filtering, echo=FALSE, eval=TRUE, warning=FALSE, fig.height=8, fig.width=10, out.width='100%', out.height='100%'}


#NOTE: CHANGE FOR TEMPO-SEQ

#Percent Mapping
#File location example - ~/scratch/2024_tPOD_Curation_Project/GSE228670/Study_id_50_PFBS_4.83_day_exposure/output/Trimmed_reads/MultiQC/MultiQC_Report_data/multiqc_star.txt

mqc_star_path <-
  normalizePath(
    file.path(
      paths$output,
      "Trimmed_reads",
      "MultiQC",
      "MultiQC_Report_data",
      "multiqc_star.txt"
    )
  )
alignment_threshold <- align_threshold
#nmr_threshold <- params$nmr_threshold

# Check if the file exists
if (!file.exists(mqc_star_path)) {
  print(
    "MultiQC did not find the QC output from the STAR tool. The multiqc_star.txt file is missing from mqc_star_path. Please review."
  )
} else {
  mqc_star <-
    list.files(
      path = paste0(
        paths$output,
        "/Trimmed_reads/MultiQC/MultiQC_Report_data"
      ),
      pattern = "multiqc_star.txt",
      full.names = TRUE
    )
  starqc <- read_delim(file = mqc_star, delim = "\t")
  starqc <- starqc %>%
    mutate(
      total_mapped_percent = multimapped_percent + uniquely_mapped_percent,
      total_mapped = uniquely_mapped + multimapped
    ) %>%
    mutate(
      passed_alignment_threshold = if_else(
        condition = total_mapped_percent >= alignment_threshold * 100,
        true = TRUE,
        false = FALSE
      )
    ) %>%
    arrange(rev(total_mapped_percent))
  
  # Reshape data for plotting
  starqc_long <- starqc %>%
    select(Sample, uniquely_mapped_percent, multimapped_percent) %>%
    pivot_longer(
      cols = c(uniquely_mapped_percent, multimapped_percent),
      names_to = "Mapping_Type",
      values_to = "Percentage"
    )
  
  # Create the stacked barplot for percentages
  gg_percent_aligned <-
    ggplot(starqc_long, aes(x = Sample, y = Percentage, fill = Mapping_Type)) +
    geom_bar(stat = "identity") +
    geom_hline(
      yintercept = alignment_threshold * 100,
      linetype = "dashed",
      color = "black"
    ) +  # Add horizontal line at 70%
    geom_text(
      data = starqc_long %>% filter(Mapping_Type == "uniquely_mapped_percent"),
      aes(y = Percentage / 2, label = sprintf("%.1f%%", Percentage)),
      color = "black",
      size = 3.5,
      angle = 90
    ) +
    geom_text(
      data = starqc_long %>% filter(Mapping_Type == "multimapped_percent"),
      aes(
        y = Percentage / 2 + starqc$uniquely_mapped_percent,
        label = sprintf("%.1f%%", Percentage)
      ),
      color = "black",
      size = 3.5,
      angle = 90
    ) +
    scale_y_continuous(
      limits = c(0, 100),
      breaks = seq(0, 100, by = 10),
      expand = c(0, 0)
    ) +
    labs(x = "Sample", y = "Percentage Mapped", fill = "Mapping Type") +
    scale_fill_manual(
      values = c(
        "uniquely_mapped_percent" = "yellow",
        "multimapped_percent" = "lightblue"
      ),
      labels = c(
        "uniquely_mapped_percent" = "Uniquely Mapped",
        "multimapped_percent" = "Multi-mapped"
      )
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  ggsave(
    gg_percent_aligned,
    file = paste0(paths$output, "/Percentage_Aligned_Threshold_Plot.pdf")
  )
  
  # Reshape data for plotting
  starqc_long_counts <- starqc %>%
    select(Sample, uniquely_mapped, multimapped) %>%
    pivot_longer(
      cols = c(uniquely_mapped, multimapped),
      names_to = "Mapping_Type",
      values_to = "Count"
    )
  
  # Function to add comma separators
  add_commas <- function(x) {
    format(x, big.mark = ",", scientific = FALSE)
  }
  
  # Create the stacked barplot for raw counts
  gg_raw_count_aligned <-
    ggplot(starqc_long_counts,
           aes(x = Sample, y = Count, fill = Mapping_Type)) +
    geom_bar(stat = "identity") +
    geom_hline(yintercept = nmr_threshold,
               linetype = "dashed",
               color = "black") +  # Add horizontal line at 10% of target seq depth
    geom_text(
      data = starqc_long_counts %>% filter(Mapping_Type == "uniquely_mapped"),
      aes(y = Count / 2, label = add_commas(Count)),
      color = "black",
      size = 3.5,
      angle = 90
    ) +
    geom_text(
      data = starqc_long_counts %>% filter(Mapping_Type == "multimapped"),
      aes(
        y = Count / 2 + starqc$uniquely_mapped,
        label = add_commas(Count)
      ),
      color = "black",
      size = 3.5,
      angle = 90
    ) +
    scale_y_continuous(labels = add_commas, expand = c(0, max(starqc_long_counts$Count) *
                                                         0.05)) +
    labs(x = "Sample", y = "Count", fill = "Mapping Type") +
    scale_fill_manual(
      values = c(
        "uniquely_mapped" = "yellow",
        "multimapped" = "lightblue"
      ),
      labels = c("uniquely_mapped" = "Uniquely Mapped", "multimapped" = "Multi-mapped")
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  ggsave(
    gg_raw_count_aligned,
    file = paste0(paths$output, "/Raw_Count_Aligned_Threshold_Plot.pdf")
  )
  
  
  #knitr::include_graphics(paste0(paths$output, "/Percentage_Aligned_Threshold_Plot.pdf"))
  #knitr::include_graphics(paste0(paths$output, "/Raw_Count_Aligned_Threshold_Plot.pdf"))
}

print(gg_percent_aligned)
```

## Total reads mapped

An absolute number of `r nmr_threshold`, representing 10% of the target sequencing depth, is used to separate outliers.

```{r total_reads_mapped_plot, echo=FALSE, eval=TRUE, warning=FALSE, fig.height=8, fig.width=10, out.width='100%', out.height='100%'}
print(gg_raw_count_aligned)
```

## Dendrogram, all samples

A tree height cutoff of `r tree_height_cutoff` is used to cut the tree and separate outliers.

Technical control samples are coloured differently.

```{r split_metadata}
############################################################################
# Dendrogram: split into experimental samples vs technical controls
############################################################################

tech_ctrl_names <- DESeqDesign %>%
  dplyr::filter(!!ensym(technical_control) == T) %>%
  dplyr::pull(original_names)

sample_names <- DESeqDesign %>%
  dplyr::filter(!!ensym(technical_control) == F) %>%
  dplyr::pull(original_names)

ref_samples <- DESeqDesign %>%
  dplyr::filter(!!ensym(reference_rna) == T) %>%
  dplyr::pull(original_names)

```

```{r dendrogram_clustering, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}



############################################################################
# Function for sorting dendrograms
############################################################################
sort_hclust <- function(...)
  as.hclust(dendsort(as.dendrogram(...)))

############################################################################
# Re-order the data by group
############################################################################
flag_order <- order(d[treatment_var])
d <- d[flag_order, ]
sampleData <- sampleData[, flag_order]

############################################################################
# CPM (used in dendrogram/cluster analysis)
############################################################################
libsize <- apply(sampleData, 2, sum)
cpm <- sampleData
for (k in 1:length(libsize)) {
  cpm[, k] <- log2((10 ^ 6) * (sampleData[, k] + 0.5) / (libsize[k] + 1))
}

############################################################################
# Dendrogram: all
############################################################################
CairoPDF(
  file = normalizePath(file.path(
    paths$output, "dendrogram_prefiltering_all.pdf"
  )),
  width = 14,
  height = 8.5,
  family = "Ubuntu"
)

dendro_before_all_samples <-
  1 - cor(as.matrix(cpm), method = clust_method)
dendro_before_all_samples <-
  sort_hclust(hclust(as.dist(dendro_before_all_samples), method = "average"))

dendro_before_all_samples <-
  as.dendrogram(dendro_before_all_samples)
colors_to_use <-
  as.numeric(as.factor(DESeqDesign[, technical_control]))
ordered_colors <-
  colors_to_use[order.dendrogram(dendro_before_all_samples)]
labels_colors(dendro_before_all_samples) <- ordered_colors

original_names <- DESeqDesign[, "original_names"]
original_names <-
  original_names[order.dendrogram(dendro_before_all_samples)]

labels_to_use <- DESeqDesign[, dendro_color_by]
labels_to_use <-
  labels_to_use[order.dendrogram(dendro_before_all_samples)]
labels_to_use <- paste(labels_to_use, original_names)

plot(
  dendro_before_all_samples %>% dendextend::set("labels", labels_to_use),
  main = "log2 CPM",
  horiz = F
)
abline(h = tree_height_cutoff, col = "red", lwd = 2)
dev.off()
```

## Dendrogram, technical controls only

```{r dendro_tech_before, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
############################################################################
# Technical Controls, Prefiltering
############################################################################
dendro_before_tech_ctrls <-
  1 - cor(as.matrix(cpm %>% dplyr::select(all_of(tech_ctrl_names))),
          method = "spearman")

if (length(dendro_before_tech_ctrls) > 2) {
  DESeqDesignTechCtrls <-
    DESeqDesign %>% dplyr::filter(original_names %in% all_of(tech_ctrl_names))
  
  dendro_before_tech_ctrls <-
    sort_hclust(hclust(as.dist(dendro_before_tech_ctrls), method = "average"))
  
  dendro_before_tech_ctrls <-
    as.dendrogram(dendro_before_tech_ctrls)
  colors_to_use <-
    as.numeric(as.factor(DESeqDesignTechCtrls[, dendro_color_by]))
  ordered_colors <-
    colors_to_use[order.dendrogram(dendro_before_tech_ctrls)]
  labels_colors(dendro_before_tech_ctrls) <- ordered_colors
  
  original_names <- DESeqDesignTechCtrls[, "original_names"]
  original_names <-
    original_names[order.dendrogram(dendro_before_tech_ctrls)]
  
  labels_to_use <- DESeqDesignTechCtrls[, dendro_color_by]
  labels_to_use <-
    labels_to_use[order.dendrogram(dendro_before_tech_ctrls)]
  labels_to_use <- paste(labels_to_use, original_names)
  
  CairoPDF(
    file = normalizePath(
      file.path(paths$output,
                "dendrogram_prefiltering_tech_controls.pdf")
    ),
    width = 14,
    height = 8.5,
    family = "Ubuntu"
  )
  
  plot(
    dendro_before_tech_ctrls %>% dendextend::set("labels", labels_to_use),
    main = "log2 CPM",
    horiz = F
  )
  abline(h = tree_height_cutoff, col = "red", lwd = 2)
  
  # Create legend
  unique_labels <- unique(DESeqDesignTechCtrls[, dendro_color_by])
  unique_colors <- unique(colors_to_use)
  
  legend("topright",
         legend = unique_labels,
         fill = unique_colors,
         title = dendro_color_by)
  
  dev.off()
}

include_safe_graphics(file.path(paths$output, "dendrogram_prefiltering_tech_controls.pdf"))

```

## Part one - Dendrogram, experimental samples only 

Coloured by `r treatment_var`.

```{r dendro_samples_before, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
############################################################################
# Experimental Samples, Prefiltering
############################################################################

CairoPDF(
  file = normalizePath(
    file.path(paths$output,
              "dendrogram_prefiltering_exp_samples.pdf")
  ),
  width = 14,
  height = 8.5,
  family = "Ubuntu"
)

dendro_before_all_exp_samples <-
  1 - cor(as.matrix(cpm %>% dplyr::select(all_of(sample_names))),
          method = "spearman")

DESeqDesignExpSamples <-
  DESeqDesign %>% dplyr::filter(original_names %in% all_of(sample_names))

dendro_before_all_exp_samples <-
  sort_hclust(hclust(as.dist(dendro_before_all_exp_samples), method = "average"))

dendro_before_all_exp_samples <-
  as.dendrogram(dendro_before_all_exp_samples)
colors_to_use <-
  as.numeric(as.factor(DESeqDesignExpSamples[, treatment_var]))
ordered_colors <-
  colors_to_use[order.dendrogram(dendro_before_all_exp_samples)]
labels_colors(dendro_before_all_exp_samples) <- ordered_colors

original_names <- DESeqDesignExpSamples[, "original_names"]
original_names <-
  original_names[order.dendrogram(dendro_before_all_exp_samples)]

labels_to_use <- DESeqDesignExpSamples[, dendro_color_by]
labels_to_use <-
  labels_to_use[order.dendrogram(dendro_before_all_exp_samples)]
labels_to_use <- paste(labels_to_use, original_names)

plot(
  dendro_before_all_exp_samples %>% dendextend::set("labels", labels_to_use),
  main = "log2 CPM",
  horiz = F
)
abline(h = tree_height_cutoff, col = "red", lwd = 2)

# Create legend
unique_labels <- unique(DESeqDesignExpSamples[, treatment_var])
unique_colors <- unique(colors_to_use)

legend("topright",
       legend = unique_labels,
       fill = unique_colors,
       title = treatment_var)

dev.off()

#include_safe_graphics(file.path(paths$output, "dendrogram_prefiltering_exp_samples.pdf"))


```

## Part two - Dendrogram, experimental samples only

Coloured by `r dendro_color_by`.

The dose coloured dendrogram is hard-coded in this version and should be removed if your experiment does not involve dose-response (and therefore won't have a dose column in the metadata).  

```{r dendro_experimental_samples_by_dose, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
############################################################################
# Experimental Samples, Prefiltering, Colored by Dose
############################################################################

CairoPDF(
  file = normalizePath(
    file.path(
      paths$output,
      "dendrogram_prefiltering_exp_samples_by_dose.pdf"
    )
  ),
  width = 14,
  height = 8.5,
  family = "Ubuntu"
)

dendro_before_all_exp_samples <-
  1 - cor(as.matrix(cpm %>% dplyr::select(all_of(sample_names))),
          method = "spearman")

DESeqDesignExpSamples <-
  DESeqDesign %>% dplyr::filter(original_names %in% all_of(sample_names))

dendro_before_all_exp_samples <-
  sort_hclust(hclust(as.dist(dendro_before_all_exp_samples), method = "average"))

dendro_before_all_exp_samples <-
  as.dendrogram(dendro_before_all_exp_samples)
colors_to_use <-
  as.numeric(as.factor(DESeqDesignExpSamples[, dendro_color_by]))
ordered_colors <-
  colors_to_use[order.dendrogram(dendro_before_all_exp_samples)]
labels_colors(dendro_before_all_exp_samples) <- ordered_colors

original_names <- DESeqDesignExpSamples[, "original_names"]
original_names <-
  original_names[order.dendrogram(dendro_before_all_exp_samples)]

labels_to_use <- DESeqDesignExpSamples[, dendro_color_by]
labels_to_use <-
  labels_to_use[order.dendrogram(dendro_before_all_exp_samples)]
labels_to_use <- paste(labels_to_use, original_names)

plot(
  dendro_before_all_exp_samples %>% dendextend::set("labels", labels_to_use),
  main = "log2 CPM",
  horiz = F
)
abline(h = tree_height_cutoff, col = "red", lwd = 2)

# Create legend
unique_labels <- unique(DESeqDesignExpSamples[, dendro_color_by])
unique_colors <- unique(colors_to_use)

legend("topright",
       legend = unique_labels,
       fill = unique_colors,
       title = dendro_color_by)

dev.off()

#include_safe_graphics(file.path(paths$output, "dendrogram_prefiltering_exp_samples_by_dose.pdf"))
```

## PCA

```{r generate_PCA_1, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
# Create PCA
require(DESeq2)
require(ggplot2)

# Row Variance - taken from genefilter package
rowVars <- function (x, ...) {
  sqr = function(x)
    x * x
  n = rowSums(!is.na(x))
  n[n <= 1] = NA
  return(rowSums(sqr(x - rowMeans(x, ...)), ...) / (n - 1))
}

# Round up to nearest 10, 100, etc
RoundUp <- function(from, to)
  ceiling(from / to) * to

# Variance Stabilization Function - from DESeq package
varStab <-
  function (object,
            blind = TRUE,
            nsub,
            fitType = "parametric") {
    if (nrow(object) < nsub) {
      stop(
        "less than 'nsub' rows,\n  it is recommended to use varianceStabilizingTransformation directly"
      )
    }
    if (is.null(colnames(object))) {
      colnames(object) <- seq_len(ncol(object))
    }
    if (is.matrix(object)) {
      matrixIn <- TRUE
      object <-
        DESeqDataSetFromMatrix(object, DataFrame(row.names = colnames(object)),
                               ~ 1)
    }
    else {
      if (blind) {
        design(object) <- ~ 1
      }
      matrixIn <- FALSE
    }
    if (is.null(sizeFactors(object)) &
        is.null(normalizationFactors(object))) {
      object <- estimateSizeFactors(object)
    }
    baseMean <- rowMeans(counts(object, normalized = TRUE))
    if (sum(baseMean > 5) < nsub) {
      stop(
        "less than 'nsub' rows with mean normalized count > 5, \n  it is recommended to use varianceStabilizingTransformation directly"
      )
    }
    object.sub <- object[baseMean > 5,]
    baseMean <- baseMean[baseMean > 5]
    o <- order(baseMean)
    idx <- o[round(seq(
      from = 1,
      to = length(o),
      length = nsub
    ))]
    object.sub <- object.sub[idx,]
    object.sub <- estimateDispersionsGeneEst(object.sub, quiet = TRUE)
    object.sub <-
      estimateDispersionsFit(object.sub, fitType = fitType,
                             quiet = TRUE)
    suppressMessages({
      dispersionFunction(object) <- dispersionFunction(object.sub)
    })
    vsd <- varianceStabilizingTransformation(object, blind = FALSE)
    if (matrixIn) {
      return(assay(vsd))
    }
    else {
      return(vsd)
    }
  }

# PCA pre-process function
pca_fun <- function(x, condition) {
  round(x) # In case counts are non-integer value
  # Create column data
  coldata <- data.frame(row.names = colnames(x), condition)
  # Make DESeqDataSetFromMatrix
  dds <-
    DESeqDataSetFromMatrix(countData = x,
                           colData = coldata,
                           design = ~ condition)
  return(dds)
}


# Define count table
ct <- sampleData # This is the count table object
b_frame <- as.data.frame(ct)
# Process data for PCA plot
condition <- factor(c(colnames(b_frame)))
b_frame_rounded <- round(b_frame)
f_dds <- pca_fun(b_frame_rounded, condition)
ntop <- 500
nsub <- RoundUp(ncol(b_frame_rounded) * 0.90, 1)
vsd <- varStab(f_dds, nsub = nsub)
rv <- rowVars(assay(vsd))
select = order(rv, decreasing = TRUE)[seq_len(min(ntop, length(rv)))]
pca = prcomp(t(assay(vsd)[select,]))
scores <- data.frame(condition, pca$x)

# Calculate the percentage of variance explained by PC1 and PC2
percent_var <- round(100 * (pca$sdev ^ 2 / sum(pca$sdev ^ 2)), 1)
pc1_label <- paste0("PC1 (", percent_var[1], "%)")
pc2_label <- paste0("PC2 (", percent_var[2], "%)")

# Plot PCA and output to PDF
pdf(file = paste0(paths$output, "/PCA.pdf"))
# Plot PC1 vs. PC2
pca_p <- ggplot(scores, aes(x = PC1, y = PC2, color = condition)) +
  geom_point(size = 3) +
  xlab(pc1_label) +
  ylab(pc2_label) +
  labs(color = 'Samples') +
  theme_minimal()
print(pca_p)
dev.off()
cat("PCA Completed\n")

#knitr::include_graphics(paste0(paths$output, "/PCA.pdf"))
print(pca_p)
```

## PCA by treatment and dose

```{r generate_PCA_2_by_dose, echo = FALSE, eval = !is.null(params$dose), fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}

##PCA by Dose##

# Row Variance - taken from genefilter package
rowVars <- function (x, ...) {
  sqr = function(x)
    x * x
  n = rowSums(!is.na(x))
  n[n <= 1] = NA
  return(rowSums(sqr(x - rowMeans(x, ...)), ...) / (n - 1))
}

# Round up to nearest 10, 100, etc
RoundUp <- function(from, to)
  ceiling(from / to) * to

# Variance Stabilization Function - from DESeq package
varStab <-
  function (object,
            blind = TRUE,
            nsub,
            fitType = "parametric") {
    if (nrow(object) < nsub) {
      stop(
        "less than 'nsub' rows,\n  it is recommended to use varianceStabilizingTransformation directly"
      )
    }
    if (is.null(colnames(object))) {
      colnames(object) <- seq_len(ncol(object))
    }
    if (is.matrix(object)) {
      matrixIn <- TRUE
      object <-
        DESeqDataSetFromMatrix(object, DataFrame(row.names = colnames(object)),
                               ~ 1)
    } else {
      if (blind) {
        design(object) <- ~ 1
      }
      matrixIn <- FALSE
    }
    if (is.null(sizeFactors(object)) &
        is.null(normalizationFactors(object))) {
      object <- estimateSizeFactors(object)
    }
    baseMean <- rowMeans(counts(object, normalized = TRUE))
    if (sum(baseMean > 5) < nsub) {
      stop(
        "less than 'nsub' rows with mean normalized count > 5, \n  it is recommended to use varianceStabilizingTransformation directly"
      )
    }
    object.sub <- object[baseMean > 5,]
    baseMean <- baseMean[baseMean > 5]
    o <- order(baseMean)
    idx <- o[round(seq(
      from = 1,
      to = length(o),
      length = nsub
    ))]
    object.sub <- object.sub[idx,]
    object.sub <- estimateDispersionsGeneEst(object.sub, quiet = TRUE)
    object.sub <-
      estimateDispersionsFit(object.sub, fitType = fitType,
                             quiet = TRUE)
    suppressMessages({
      dispersionFunction(object) <- dispersionFunction(object.sub)
    })
    vsd <- varianceStabilizingTransformation(object, blind = FALSE)
    if (matrixIn) {
      return(assay(vsd))
    } else {
      return(vsd)
    }
  }

# PCA pre-process function
pca_fun <- function(x, condition) {
  round(x) # In case counts are non-integer value
  # Create column data
  coldata <- data.frame(row.names = colnames(x), condition)
  # Make DESeqDataSetFromMatrix
  dds <-
    DESeqDataSetFromMatrix(countData = x,
                           colData = coldata,
                           design = ~ condition)
  return(dds)
}

# Process data for PCA plot
condition <- factor(c(colnames(b_frame)))
b_frame_rounded <- round(b_frame)
f_dds <- pca_fun(b_frame_rounded, condition)
ntop <- 500
nsub <- RoundUp(ncol(b_frame_rounded) * 0.90, 1)
vsd <- varStab(f_dds, nsub = nsub)
rv <- rowVars(assay(vsd))
select = order(rv, decreasing = TRUE)[seq_len(min(ntop, length(rv)))]
pca = prcomp(t(assay(vsd)[select,]))

#Assuming the first column in "d" is the sample names
colnames(d)[1] <- "Run"

scores <- data.frame(Run = rownames(pca$x), pca$x)
dose_col <- ensym(dose)
compound_col <- ensym(treatment_var)
meta_data <- d %>%
  dplyr::select("Run",!!dose_col,!!compound_col)
meta_data[[as.character(dose_col)]] <-
  as.factor(meta_data[[as.character(dose_col)]]) #set as factor
meta_data[[as.character(compound_col)]] <-
  as.factor(meta_data[[as.character(compound_col)]]) #set as factor

# Merge with metadata for coloring
scores <- merge(scores, meta_data, by.x = "Run", by.y = "Run")

# Calculate the percentage of variance explained by PC1 and PC2
percent_var <- round(100 * (pca$sdev ^ 2 / sum(pca$sdev ^ 2)), 1)
pc1_label <- paste0("PC1 (", percent_var[1], "%)")
pc2_label <- paste0("PC2 (", percent_var[2], "%)")

# Plot PCA and output to PDF
pdf(file = paste0(paths$output, "/PCA_dose.pdf"))
# Plot PC1 vs. PC2
pca_p <-
  ggplot(scores,
         aes(
           x = PC1,
           y = PC2,
           color = !!dose_col,
           label = Run,
           shape = !!compound_col
         )) +
  geom_point(size = 3) +
  geom_text(vjust = -0.5, hjust = 1) +
  xlab(pc1_label) +
  ylab(pc2_label) +
  labs(color = 'Dose', shape = 'Compound') +
  theme_minimal()
print(pca_p)
dev.off()
cat("PCA Colored by Dose Completed\n")

#knitr::include_graphics(paste0(paths$output, "/PCA_dose.pdf"))
print(pca_p)

filter_pca_variance <- function(scores, threshold = 20) {
  pca_filter_results_list <- NULL
  for (k in unique(scores[[treatment_var]])) {
    scores_filt <- scores %>%
      dplyr::rename(Sample = Run) %>%
      dplyr::filter(!!sym(treatment_var) == k)
    dose_groups <- unique(scores_filt[[dose]])
    pca_filter_results <- data.frame(
      Sample = character(),
      PC1_var = numeric(),
      PC2_var = numeric(),
      Status = character(),
      stringsAsFactors = FALSE
    )
    pca_filter_results[[dose]] <- character()
    pca_filter_results[[treatment_var]] <- character()
    
    
    for (i in dose_groups) {
      dose_samples <- scores_filt[scores_filt[[dose]] == i,]
      if (nrow(dose_samples) > 2) {
        pc1_median <- median(dose_samples$PC1)
        pc2_median <- median(dose_samples$PC2)
        
        # Calculate the variance percentage
        dose_samples$PC1_var <- abs(dose_samples$PC1 - pc1_median)
        dose_samples$PC2_var <- abs(dose_samples$PC2 - pc2_median)
        
        # Determine pass/fail status
        dose_samples$Status <-
          ifelse(
            dose_samples$PC1_var > threshold |
              dose_samples$PC2_var > threshold,
            "FAIL",
            "PASS"
          )
        
        # Append to the results data frame
        pca_filter_results <-
          rbind(pca_filter_results, dose_samples[, c("Sample",
                                                     dose,
                                                     treatment_var,
                                                     "PC1_var",
                                                     "PC2_var",
                                                     "Status")])
      } else {
        print(
          "Your experimental design does not include enough replicates... skipping filtering. Your samples will automatically PASS and you will have to review the PCA plot yourself and decide if you want to remove samples."
        )
        
        dose_samples$PC1_var <- dose_samples$PC1
        dose_samples$PC2_var <- dose_samples$PC1
        
        # Determine pass/fail status
        dose_samples$Status <- "PASS"
        
        # Append to the results data frame
        pca_filter_results <-
          rbind(pca_filter_results, dose_samples[, c("Sample",
                                                     dose,
                                                     treatment_var,
                                                     "PC1_var",
                                                     "PC2_var",
                                                     "Status")])
      }
    }
    pca_filter_results_list[[k]] <- pca_filter_results
  }
  # Combine all results into a single data frame
  combined_results <- bind_rows(pca_filter_results_list)
  
  return(combined_results)
}

# After the PCA plot generation, use the filtering function
pca_filter_results <-
  filter_pca_variance(scores, threshold = PCA_cutoff * 100)
```

## Number of active probes (NCov5/NCovn)

The proportion of probes having >5 uniquely mapped reads are calculated. Outliers on that metric (i.e., outside 3XIQR) are removed from analysis.

```{r NCov5_boxplot, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
######################################################################################
# Ncov5 The number of probes with at least 5 uniquely mapped reads.
######################################################################################
# Tukey's Outer Fence cutoff - 3*IQR
Ncov5 <- data.frame(Sample = names(sampleData))
n_genes <- nrow(sampleData)
Ncov5$value <-
  apply(sampleData, 2, function(x)
    length(x[x > 4])) / n_genes
percent_active_probes <- boxplot(Ncov5$value, range = 3, plot = F)
failed_Ncov5 <-
  Ncov5[Ncov5$value < percent_active_probes$stats[1, 1] |
          Ncov5$value > percent_active_probes$stats[5, 1],]

# Determine the y-axis limits to accommodate all points, including outliers if they exist
ylim_range <- range(Ncov5$value)
if (nrow(failed_Ncov5) > 0) {
  ylim_range <- range(c(Ncov5$value, failed_Ncov5$value))
}

# Create the base plot
boxplot(
  Ncov5$value,
  range = 3,
  plot = TRUE,
  ylab = "Proportion of probes with >5 uniquely mapped reads",
  main = "NCov5",
  xlab = "All samples",
  outline = FALSE,
  ylim = ylim_range
)

# Jitter x-coordinates for all points
jittered_x <- jitter(rep(1, length(Ncov5$value)), amount = 0.2)

# Add jittered points, coloring the outliers in red
points(
  jittered_x,
  Ncov5$value,
  col = ifelse(
    Ncov5$value < percent_active_probes$stats[1, 1] |
      Ncov5$value > percent_active_probes$stats[5, 1],
    "red",
    "black"
  ),
  pch = 16
)

# Add sample names to the outliers, if any exist, using the same jittered x-coordinates
if (nrow(failed_Ncov5) > 0) {
  outlier_indices <- which(
    Ncov5$value < percent_active_probes$stats[1, 1] |
      Ncov5$value > percent_active_probes$stats[5, 1]
  )
  
  text(
    jittered_x[outlier_indices],
    Ncov5$value[outlier_indices],
    labels = Ncov5$Sample[outlier_indices],
    pos = 4,
    col = "red"
  )
}
```

## Number of probes capturing 80% of signal (NSig80)

The number of probes it takes to capture 80% of the signal is first calculated, and samples falling outside of 3X IQR are removed from downstream analysis.

```{r NSig80_boxplot, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
######################################################################################
# Nsig80 - The number of probes capturing the top 80% of signal in a sample.
######################################################################################
# Tukey's Outer Fence cutoff - 3*IQR
# (include test samples, vehicle controls, and reference chemical treatments)

### Using some of the EPA code for now:
countStats <- function(counts,
                       nsig = getOption("httrStatNsig", default = 0.8)) {
  # Load required pkgs
  require(foreach)
  # Store results in a vector
  st <- vector()
  # Drop probes w/ no reads (this is for efficiency, should not impact final Nsig values)
  counts_nz <- counts[counts > 0]
  # Sort in decreasing order
  counts_nz <- sort(counts_nz, decreasing = T)
  # Compute cumulative sum of counts starting from highest count probe
  cumCounts <- cumsum(counts_nz)
  # Convert cumulative sums to cumulative proportions
  cumProp <- cumCounts / sum(counts_nz)
  # Compute the minimum number of probes to capture X% of total reads
  if (length(nsig) > 0) {
    ns <-
      foreach(prop = nsig, .combine = 'c') %do% {
        min(which(cumProp > prop))
      }
    names(ns) <- paste0("n_sig", nsig * 100)
    st <- append(st, ns)
  }
  return(st)
}

# ref <- apply(sampleData/QAQC$NMR, 2, median)
# sig80 <- quantile(ref, prob = 0.8)
#
# QAQC$Nsig80 <- 0
#
# for(k in 1:nrow(QAQC)){
#   flag80pct <- sampleData[,k] > sig80 * QAQC$NMR[k]
#   QAQC$Nsig80[k] <- length(sampleData[flag80pct, 1])/n_samples
# }
#

# Create a data frame for Nsig80 values
Nsig80 <- data.frame(Sample = names(sampleData))

# Calculate the number of probes it takes to capture 80% of the signal
Nsig80$value <- apply(sampleData, 2, countStats)

# Generate boxplot stats without plotting
probes_capturing_top_80 <-
  boxplot(Nsig80$value, range = 3, plot = FALSE)

# Identify outliers based on the 3x IQR rule
failed_Nsig80 <-
  Nsig80[Nsig80$value < probes_capturing_top_80$stats[1, 1] |
           Nsig80$value > probes_capturing_top_80$stats[5, 1], ]

# Determine the y-axis limits to accommodate all points, including outliers if they exist
ylim_range <- range(Nsig80$value)
if (nrow(failed_Nsig80) > 0) {
  ylim_range <- range(c(Nsig80$value, failed_Nsig80$value))
}

# Create the base boxplot with dynamic y-axis limits
boxplot(
  Nsig80$value,
  range = 3,
  plot = TRUE,
  ylab = "# of probes it takes to capture 80% of the signal",
  main = "Nsig80",
  xlab = "All samples",
  outline = FALSE,
  ylim = ylim_range
)

# Jitter x-coordinates for all points
jittered_x <- jitter(rep(1, length(Nsig80$value)), amount = 0.2)

# Add jittered points, coloring the outliers in red
points(
  jittered_x,
  Nsig80$value,
  col = ifelse(
    Nsig80$value < probes_capturing_top_80$stats[1, 1] |
      Nsig80$value > probes_capturing_top_80$stats[5, 1],
    "red",
    "black"
  ),
  pch = 16
)

# Add sample names to the outliers, if any exist, using the same jittered x-coordinates
if (nrow(failed_Nsig80) > 0) {
  outlier_indices <- which(
    Nsig80$value < probes_capturing_top_80$stats[1, 1] |
      Nsig80$value > probes_capturing_top_80$stats[5, 1]
  )
  
  text(
    jittered_x[outlier_indices],
    Nsig80$value[outlier_indices],
    labels = Nsig80$Sample[outlier_indices],
    pos = 4,
    col = "red"
  )
}
```

## Gini coefficient

The Gini coefficient is computed for each sample based on the distribution of raw counts for all probes including those with 0 aligned reads. Samples with Gini coefficients >`r gini_cutoff` are removed from the analysis.

```{r gini_base_plot, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
######################################################################################
# Gini coefficient - Gini coefficient computed for each sample based on the distribution of
# raw counts for all probes including those with 0 aligned reads
######################################################################################
# Define the Gini cutoff threshold
#gini_cutoff <- 0.95 #Default

# Create a data frame for Gini coefficients
Gini <- data.frame(Sample = names(sampleData))

# Calculate the Gini coefficient for each sample
Gini$value <- apply(sampleData, 2, function(x)
  gini(x))

# Identify samples with Gini values exceeding the cutoff
failed_gini <- Gini[Gini$value > gini_cutoff,]

# Determine the y-axis limits to accommodate all points, and extend upwards to 1
ylim_range <- range(Gini$value)
ylim_range[2] <- 1  # Set the upper limit of the y-axis to 1

# Create a boxplot of the Gini coefficients with dynamic y-axis limits
boxplot(
  Gini$value,
  main = "Gini Coefficients",
  ylab = "Gini Coefficient",
  xlab = "All samples",
  outline = FALSE,
  ylim = ylim_range
)



# Jitter x-coordinates for all points
jittered_x <- jitter(rep(1, length(Gini$value)), amount = 0.2)

# Add jittered points, coloring the outliers in red
points(
  jittered_x,
  Gini$value,
  col = ifelse(Gini$value > gini_cutoff, "red", "black"),
  pch = 16
)

# Add sample names to the outliers, if any exist, using the same jittered x-coordinates
if (nrow(failed_gini) > 0) {
  outlier_indices <- which(Gini$value > gini_cutoff)
  
  text(
    jittered_x[outlier_indices],
    Gini$value[outlier_indices],
    labels = Gini$Sample[outlier_indices],
    pos = 4,
    col = "red"
  )
}
```

## Additional misc. QC metrics

```{r generate_additional_QC_figures_1, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
#Read counts table from command line
ct <- sampleData # This is the count table object
if (!is.null(mu)) {
  mu_t <- t(mu) #This is the mapped-unmapped file from TempO-Seq
} else {
  print(
    "WARNING: No Mapped-unmapped file located. If your data is TempoSeq, please review. If not, proceeding..."
  )
}
#Create Dendrogram
b_frame <- as.data.frame(ct)
new_frame <- apply(b_frame, 2, as.numeric)
dat <- as.matrix(new_frame)
cd <- dist(t(dat))
cc <- hclust(cd)
hcd = as.dendrogram(cc)

pdf(file = paste0(paths$output, "/dendrogram.pdf"))
par(cex = 0.8)
plot(hcd, main = "Euclidean distance cluster dendrogram", ylab = "Height")
dev.off()
cat("Dendrogram Completed\n")

#knitr::include_graphics(paste0(paths$output, "/dendrogram.pdf"))
par(cex = 0.8)
plot(hcd, main = "Euclidean distance cluster dendrogram", ylab = "Height")

#If mapped_unmapped table is present - create bar plot
if (!is.null(mu)) {
  #mu <- read.table(mu, sep=",", header=T, row.names=1, stringsAsFactors = F, check.names = F)
  
  #Generate bar plot of total reads/sample and the mapped and unmapped portion.
  ll2 <- as.matrix(mu_t)
  
  # Define the threshold
  threshold <- params$nmr_threshold
  
  mettol <- seq(1, dim(ll2)[2], 50)
  pdf(file = paste0(paths$output, "/barplot_mapped_unmapped.pdf"))
  par(cex = 1.5)
  par(las = 2)
  
  for (i in 1:length(mettol)) {
    if (dim(ll2)[2] >= (mettol[i] + 49)) {
      barplot(
        as.matrix(ll2[, mettol[i]:(mettol[i] + 49)]),
        col = c("yellow", "orange"),
        ylab = "read counts",
        xlab = "sample name",
        cex.axis = 0.5,
        cex.names = 0.5
      )
      abline(
        h = threshold,
        col = "red",
        lwd = 2,
        lty = 2
      )
      legend(
        "topleft",
        c("unmapped", "mapped", "10% target read depth"),
        fill = c("yellow", "orange", "red"),
        cex = 0.7
      )
    } else{
      barplot(
        as.matrix(ll2[, mettol[i]:dim(ll2)[2]]),
        col = c("yellow", "orange"),
        ylab = "read counts",
        xlab = "sample name",
        cex.axis = 0.5,
        cex.names = 0.5
      )
      abline(
        h = threshold,
        col = "red",
        lwd = 2,
        lty = 2
      )
      legend(
        "topleft",
        c("unmapped", "mapped", "10% target read depth"),
        fill = c("yellow", "orange", "red"),
        cex = 0.7
      )
    }
  }
  dev.off()
  cat("Bar plot Completed\n")
  
  knitr::include_graphics(paste0(paths$output, "/barplot_mapped_unmapped.pdf"))
}
```

# {-}

# Sample filtering summary {.tabset}

## Q30 scores (percentage of bases over Q30 Score)

With a threshold cutoff of `r q30_cutoff*100`%

```{r q30_QAQC}
######################################################################################
#Percentage of bases over Q30 Score
#And percentage difference of Q30 score between read1 and read2 for paired data
######################################################################################
# DEFAULT: Reject < 0.7
results_df <- results_df %>%
  dplyr::rename(Sample = sample_name)

QAQC <-
  data.frame(Sample = names(sampleData)) #Column names of count matrix/sampleData are the sample names

QAQC <- QAQC %>%
  dplyr::left_join(results_df %>% select(Sample, q30_after), by = "Sample") %>%
  dplyr::rename(q30 = q30_after)
failed_q30 <- QAQC[QAQC$q30 < q30_cutoff * 100, ]

# Check and print flagged samples
if (nrow(failed_q30) > 0) {
  print("Samples Flagged:")
  flagged_samples <- d %>%
    dplyr::filter(original_names %in% failed_q30$Sample) %>%
    dplyr::pull(original_names)
  print(flagged_samples)
} else {
  print("No samples failed the Q30 threshold.")
}
```

## Q30 scores - paired data only (percentage difference of Q30 score between read1 and read2)

With a threshold cutoff of `r align_threshold*100`% difference between read1 and read2. Note: Only applicable for paired-end read data.

```{r q30_difference_between_Read1_read2_QAQC}
######################################################################################
#Percentage of bases over Q30 Score
#And percentage difference of Q30 score between read1 and read2 for paired data
######################################################################################
# DEFAULT: Reject > 0.25

QAQC <- QAQC %>%
  dplyr::left_join(results_df %>% select(Sample, diff_r1_r2_after), by = "Sample") %>%
  dplyr::rename(diff_r1_r2_q30 = diff_r1_r2_after)
failed_diff_q30 <-
  QAQC[QAQC$diff_r1_r2_q30 > forward_reverse_q30_diff_cutoff * 100, ]

# Check and print flagged samples
if (nrow(failed_diff_q30) > 0) {
  print("Samples Flagged:")
  flagged_samples <- d %>%
    dplyr::filter(original_names %in% failed_diff_q30$Sample) %>%
    dplyr::pull(original_names)
  print(flagged_samples)
} else {
  print("No samples failed the Q30 difference threshold.")
}
```

## Percent alignment

With a threshold cutoff of `r align_threshold*100`%

```{r alignment_QAQC}
######################################################################################
# Percentage Alignment
######################################################################################
# Add starqc to QAQC object
QAQC <- QAQC %>%
  dplyr::left_join(starqc %>% select(Sample, total_mapped_percent), by = "Sample") %>%
  dplyr::rename(pct_mapped = total_mapped_percent)
failed_alignment <- QAQC[QAQC$pct_mapped < align_threshold * 100, ]

# Check and print flagged samples
if (nrow(failed_alignment) > 0) {
  print("Samples Flagged:")
  flagged_samples <- d %>%
    dplyr::filter(original_names %in% failed_alignment$Sample) %>%
    dplyr::pull(original_names)
  print(flagged_samples)
} else {
  print("No samples failed the alignment threshold.")
}
```

## Total mapped reads

Samples less than `r nmr_threshold` aligned reads removed.

```{r num_mapped_reads_QAQC}
######################################################################################
# Additional QC Metrics
######################################################################################
# NMR Number of mapped reads, defined as sum of total read counts summed over all detected probes
######################################################################################
# Reject < 300000 or Threshold = 10% of target depth
# Removes various types of failed samples

# Add NMR (Number of Mapped Reads) to the existing QAQC object
QAQC <- QAQC %>%
  dplyr::left_join(
    data.frame(Sample = names(sampleData), 
               NMR = apply(sampleData, 2, sum)), 
    by = "Sample"
  )
failed_read_threshold <- QAQC[QAQC$NMR < nmr_threshold, ]

# Check if any samples failed the NMR threshold and print them
if (nrow(failed_read_threshold) > 0) {
  print("Samples Flagged:")
  flagged_samples <- d %>%
    dplyr::filter(original_names %in% failed_read_threshold$Sample) %>%
    dplyr::pull(original_names)
  print(flagged_samples)
} else {
  print("No samples failed the NMR threshold.")
}

if (Platform == "TempO-Seq") {
  print("TempO-Seq only... Under development")
  # QAQC$pct_mapped <-
  # failed_alignment_threshold <- QAQC[QAQC$pct_mapped < align_threshold,]
  #
  # # Samples failing
  # print("Samples Flagged:")
  # d %>%
  #   dplyr::filter(original_names %in% failed_alignment_threshold$Sample) %>%
  #   dplyr::pull(original_names)
}

```

## Pearson correlation distance (dendrogram)

In the code below, a `r clust_method` distance of `r tree_height_cutoff` is used to cut the tree and separate outliers. This is a sample clustering technique.

```{r filtering_dendrogram_QAQC}
############################################################################
# Filtering
############################################################################

tree_groups <-
  cutree(dendro_before_all_samples, h = tree_height_cutoff)
n <- table(tree_groups)
n <- n[n == 1]

print("Samples Flagged:")

if (length(n) > 0) {  # Ensure the length of n is greater than 0
  flag_cluster <- d$original_names %in% names(tree_groups[tree_groups %in% as.integer(names(n))])
  
  # Write the flagged samples to a file
  write.table(
    d[flag_cluster, ],
    normalizePath(
      file.path(paths$processed, "outliers_cluster_analysis.txt")
    ),
    sep = "\t",
    row.names = FALSE,
    col.names = TRUE,
    quote = FALSE
  )
  
  # Print the group assignments for flagged samples
  print(d$group[flag_cluster])
} else {
  print("No samples were flagged in the clustering analysis.")
}
```

## Dose group clustering variance (from PCA)

With a threshold cutoff of `r PCA_cutoff*100`%

```{r PCA_variance_QAQC}
######################################################################################
# PCA Variance
######################################################################################
# Add pca_filter_results to QAQC object
QAQC <- QAQC %>%
  dplyr::left_join(pca_filter_results %>% select(Sample, PC1_var, PC2_var), by = "Sample")
failed_PC1 <- QAQC[QAQC$PC1_var > PCA_cutoff * 100, ]
failed_PC2 <- QAQC[QAQC$PC2_var > PCA_cutoff * 100, ]

# Check if any samples failed the PCA variance threshold
print("Samples Flagged:")
flagged_samples <- d %>%
  dplyr::filter(original_names %in% failed_PC1$Sample | original_names %in% failed_PC2$Sample) %>%
  dplyr::pull(original_names)

if (length(flagged_samples) > 0) {
  print(flagged_samples)
} else {
  print("No samples failed the PCA variance thresholds.")
}
```

## Number of active probes (NCovn)

The number of probes having >5 uniquely mapped reads are calculated. Outliers on that metric (i.e., outside 3XIQR) are removed from analysis.

```{r ncov5_QAQC}
######################################################################################
# Ncov5 The number of probes with at least 5 uniquely mapped reads.
######################################################################################
# Tukey's Outer Fence cutoff - 3*IQR
n_genes <- nrow(sampleData)
QAQC$Ncov5 <-
  apply(sampleData, 2, function(x)
    length(x[x > 4])) / n_genes
percent_active_probes <- boxplot(QAQC$Ncov5, range = 3, plot = F)
failed_Ncov5 <-
  QAQC[QAQC$Ncov5 < percent_active_probes$stats[1, 1] |
         QAQC$Ncov5 > percent_active_probes$stats[5, 1], ]

# Check if any samples failed the Ncov5 threshold
print("Samples Flagged:")
flagged_samples <- d %>%
  dplyr::filter(original_names %in% failed_Ncov5$Sample) %>%
  dplyr::pull(original_names)

if (length(flagged_samples) > 0) {
  print(flagged_samples)
} else {
  print("No samples failed the Ncov5 threshold.")
}
```

## Number of probes capturing 80% of signal (NSig80)

The number of probes capturing 80% of the signal is first calculated, and samples falling outside of 3X IQR are removed from downstream analysis.

```{r nsig80_QAQC}
######################################################################################
# Nsig80 - The number of probes capturing the top 80% of signal in a sample.
######################################################################################
# Tukey's Outer Fence cutoff - 3*IQR
# (include test samples, vehicle controls, and reference chemical treatments)

QAQC$Nsig80 <- apply(sampleData, 2, countStats)

probes_capturing_top_80 <- boxplot(QAQC$Nsig80, range = 3, plot = F)
failed_Nsig80 <-
  QAQC[QAQC$Nsig80 < probes_capturing_top_80$stats[1, 1] |
         QAQC$Nsig80 > probes_capturing_top_80$stats[5, 1], ]

# Check if any samples failed the Nsig80 threshold
print("Samples Flagged:")
flagged_samples <- d %>%
  dplyr::filter(original_names %in% failed_Nsig80$Sample) %>%
  dplyr::pull(original_names)

if (length(flagged_samples) > 0) {
  print(flagged_samples)
} else {
  print("No samples failed the Nsig80 threshold.")
}

```

## Gini coefficient

The Gini coefficient is computed for each sample based on the distribution of raw counts for all probes including those with 0 aligned reads. Samples with Gini coefficients >`r gini_cutoff` are removed from the analysis.

```{r gini_QAQC}
######################################################################################
# Gini coefficient - Gini coefficient computed for each sample based on the distribution of
# raw counts for all probes including those with 0 aligned reads
######################################################################################
# DEFAULT: Reject > 0.95
QAQC$Gini <- apply(sampleData, 2, function(x)
  gini(x))
failed_gini <- QAQC[QAQC$Gini > gini_cutoff, ]

# Check if any samples failed the Gini threshold
print("Samples Flagged:")
flagged_samples <- d %>%
  dplyr::filter(original_names %in% failed_gini$Sample) %>%
  dplyr::pull(original_names)

if (length(flagged_samples) > 0) {
  print(flagged_samples)
} else {
  print("No samples failed the Gini coefficient threshold.")
}
```

# {-}

# Sample-to-sample correlations {.tabset}

## All samples

This shows the Pearson correlation of log2-normalized CPM of read counts across all samples.

```{r correlation_1, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
#From header: , fig.width = 11, fig.height = 10
ref_correlations_all <- cor(as.matrix(cpm),
                            method = "pearson")

correlation_df_all <- DESeqDesign %>%
  filter(original_names %in% colnames(ref_correlations_all))

rownames(correlation_df_all) <- correlation_df_all$original_names
correlation_df_all <-
  correlation_df_all[colnames(ref_correlations_all), ]

correlation_df_all_heatmap <-
  correlation_df_all[, c(unlist(groups[[1]]),
                         technical_control,
                         reference_rna,
                         solvent_control)]

correlation_df_all_heatmap$technical_control <-
  as.numeric(correlation_df_all_heatmap$technical_control)
correlation_df_all_heatmap$reference_rna <-
  as.numeric(correlation_df_all_heatmap$reference_rna)
correlation_df_all_heatmap$solvent_control <-
  as.numeric(correlation_df_all_heatmap$solvent_control)
correlation_df_all_heatmap$Compound <-
  as.factor(correlation_df_all_heatmap$Compound)

pheatmap(
  ref_correlations_all,
  show_rownames = T,
  show_colnames = T,
  border_color = NA,
  annotation_col = correlation_df_all_heatmap,
  filename = file.path(paths$output, "Heatmap_Pearson_log2CPM_all_samples.pdf")
)

include_safe_graphics(file.path(paths$output, "Heatmap_Pearson_log2CPM_all_samples.pdf"))

```

## Experimental samples only

This shows the Pearson correlation of log2-normalized CPM of read counts across experimental samples.  **Technical controls are excluded.**

This first plot shows every sample in the study:

```{r correlation_2, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
ref_correlations_samples <- cor(as.matrix(cpm %>%
                                            dplyr::select(all_of(sample_names))),
                                method = "pearson")

correlation_df_samples <- DESeqDesign %>%
  filter(original_names %in% colnames(ref_correlations_samples))

rownames(correlation_df_samples) <-
  correlation_df_samples$original_names
correlation_df_samples <-
  correlation_df_samples[colnames(ref_correlations_samples), ]

correlation_df_samples_heatmap <-
  correlation_df_samples[, c(unlist(groups[[1]]),
                             technical_control,
                             reference_rna,
                             solvent_control)]

correlation_df_samples_heatmap$technical_control <-
  as.numeric(correlation_df_samples_heatmap$technical_control)
correlation_df_samples_heatmap$reference_rna <-
  as.numeric(correlation_df_samples_heatmap$reference_rna)
correlation_df_samples_heatmap$solvent_control <-
  as.numeric(correlation_df_samples_heatmap$solvent_control)
correlation_df_samples_heatmap$Compound <-
  as.factor(correlation_df_samples_heatmap$Compound)

pheatmap(
  ref_correlations_samples,
  show_rownames = T,
  show_colnames = T,
  border_color = NA,
  annotation_col = correlation_df_samples_heatmap,
  filename = file.path(
    paths$output,
    "Heatmap_Pearson_log2CPM_experimental_samples.pdf"
  )
)

include_safe_graphics(file.path(
  paths$output,
  "Heatmap_Pearson_log2CPM_experimental_samples.pdf"
))

```

# {-}

## cellWise PCA outlier map {.tabset}

These plots show correlations within each experimental grouping. Faceted by the treatment variable (e.g., Chemical/Compound)

```{r PCA_outlier_map, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', echo = FALSE, results='asis'}
### To double check a group of interest... Generate and include PCA outlier maps in tabsets
facets <- unique(DESeqDesignExpSamples[, treatment_var])
cor_list <- list()

for (i in seq_along(facets)) {
  samples_in_facet <- DESeqDesignExpSamples[DESeqDesignExpSamples[[treatment_var]] == facets[i], "original_names"]
  cpm_subset <- as.matrix(cpm %>% dplyr::select(all_of(samples_in_facet)))
  pca_subset <- rrcov::PcaGrid(t(cpm_subset))
  
  # Generate the PCA outlier map and save as a unique PDF file
  file_name <- paste0("OutlierMap_", facets[i], "_Pearson_log2CPM_experimental_samples.pdf")
  pdf(file = file.path(paths$output, file_name))
  cellWise::outlierMap(pca_subset)
  dev.off()
  
  # Create a tab for each facet and include the corresponding PCA outlier map
  cat("### ", facets[i], "\n\n")
  cat("![", facets[i], "](", file.path(paths$output, file_name), ")\n\n")
}
```

## {-}

## Correlation Heatmap for sample groups {.tabset}

These plots show correlations within each experimental grouping. Faceted by the treatment variable (e.g., Chemical/Compound)

```{r Correlation_Heatmap, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', echo=FALSE, results='asis'}
# Generate correlation heatmaps and include them in tabsets
facets <- unique(DESeqDesignExpSamples[, treatment_var])
cor_list <- list()

for (i in seq_along(facets)) {
  samples_in_facet <- DESeqDesignExpSamples[DESeqDesignExpSamples[[treatment_var]] == facets[i], "original_names"]
  cpm_subset <- as.matrix(cpm %>% dplyr::select(all_of(samples_in_facet)))
  
  # Calculate correlations and prepare for heatmap
  correlations <- cor(cpm_subset, method = "pearson")
  correlation_df <- DESeqDesign %>%
    filter(original_names %in% colnames(correlations))
  
  row.names(correlation_df) <- correlation_df$original_names
  correlation_df <- correlation_df[colnames(correlations), ]
  correlation_df <- as.data.frame(correlation_df[unlist(groups[[1]][1])])
  
  # Generate the correlation heatmap and save as a unique PDF file
  file_name <- paste0("Group_Heatmap_", facets[i], "_Pearson_log2CPM_experimental_samples.pdf")
  pheatmap(
    correlations,
    annotation_col = correlation_df,
    display_numbers = TRUE,
    cutree_cols = 2,
    cutree_rows = 2,
    filename = file.path(paths$output, file_name)
  )
  
  # Create a tab for each facet and include the corresponding heatmap
  cat("### ", facets[i], "\n\n")
  cat("![", facets[i], "](", file.path(paths$output, file_name), ")\n\n")
  
  # Store correlation data for further analysis
  correlations <- as.data.frame(correlations)
  correlations$original_names <- row.names(correlations)
  cor_distribution <- correlations %>%
    mutate(mean = rowMeans(across(where(is.numeric)))) %>%
    dplyr::select(mean, original_names) %>%
    mutate(facet = facets[i])
  cor_list[[i]] <- cor_distribution
}
```

## {-}

# Distribution of Sample-to-sample correlations {.tabset}

## Mean of per-sample correlations with every other sample in the study

In other words, for each sample, what is its mean correlation with every other sample?

```{r correlations_4, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
# Create the correlation data frame
cor_df1 <- as.data.frame(ref_correlations_samples)
cor_df1$original_names <- row.names(cor_df1)

# Calculate the study-wide correlation means
cor_distribution_all <- cor_df1 %>%
  mutate(mean = rowMeans(across(where(is.numeric)))) %>%
  dplyr::select(mean, original_names)

# Set dynamic lower limit for y-axis
ymin <- min(cor_distribution_all$mean, na.rm = TRUE)

# Create the plot with dynamic y-axis limits and minimal theme
gg <- ggplot(cor_distribution_all, aes(x = "", y = mean)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(position = position_jitter(seed = 1, width = 0.2)) +
  geom_text(
    aes(label = original_names),
    position = position_jitter(seed = 1, width = 0.2),
    hjust = 0,
    vjust = 0,
    check_overlap = TRUE
  ) +
  ylim(ymin, 1) +
  ylab("Mean Pearson Correlation Coefficient") +
  xlab("") +  # Empty x-axis label since it's study-wide
  theme_minimal()

# Save the plot
ggsave(gg,
       file = paste0(paths$output, "/Samp_for_samp_corr_comparison_boxplot.pdf"))

# Print the plot
print(gg)
```

## Mean of per-sample correlations with every other sample in its corresponding group

In other words, for each sample, what is its mean correlation with every other sample **within in its experimental grouping**?

```{r correlations_5, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
# MEANS BY CHEMICAL
cor_means_by_chem <- data.table::rbindlist(cor_list)
# Set dynamic lower limit for y-axis
ymin <- min(cor_means_by_chem$mean, na.rm = TRUE)

# Create the plot with dynamic y-axis limits, minimal theme, and meaningful labels
gg <- ggplot(cor_means_by_chem, aes(facet, mean)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(position = position_jitter(seed = 1, width = 0.2)) +
  geom_text(
    aes(label = original_names),
    position = position_jitter(seed = 1, width = 0.2),
    hjust = 0,
    vjust = 0,
    check_overlap = TRUE
  ) +
  ylim(ymin, 1) +
  ylab(paste0("Mean Pearson Correlation Coefficient by ", treatment_var)) +
  xlab(treatment_var) +
  theme_minimal()

# Save the plot
ggsave(
  gg,
  file = paste0(
    paths$output,
    "/Samp_for_samp_corr_by_chemical_comparison_boxplot.pdf"
  )
)

# Print the plot
print(gg)
```

## Mean of per-sample correlations with every other sample within the same dose group

In other words, for each sample, what is its mean correlation with every other sample **within its dose group**?

```{r correlations_within_dose_group_6, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
# Assuming 'dose_var' is the variable representing the dose group
dose_var <- dose

# Initialize list for storing correlation distributions
cor_list_by_group <- list()

# Iterate over each treatment and dose combination
for (treatment in unique(DESeqDesignExpSamples[[treatment_var]])) {
  for (dose_n in unique(DESeqDesignExpSamples[[dose_var]])) {
    # Get samples in the current treatment and dose_n group
    samples_in_group <- DESeqDesignExpSamples[DESeqDesignExpSamples[[treatment_var]] == treatment &
                                                DESeqDesignExpSamples[[dose_var]] == dose_n, "original_names"]
    
    # Check the number of samples in the group
    if (length(samples_in_group) == 1) {
      message(paste(
        "Skipping group",
        treatment,
        dose_n,
        "because it has only 1 sample."
      ))
      cor_list_by_group[[paste(treatment, dose_n, sep = "_")]] <-
        list()
      next
    } else if (length(samples_in_group) == 2) {
      message(
        paste(
          "Warning: Group",
          treatment,
          dose_n,
          "has only 2 samples. Correlation calculation is not meaningful."
        )
      )
      cor_list_by_group[[paste(treatment, dose_n, sep = "_")]] <-
        list()
      next
    }
    
    # Proceed with correlation calculation if 3 or more samples
    if (length(samples_in_group) >= 3) {
      # Subset CPM data for the current group
      cpm_subset <-
        as.matrix(cpm %>% dplyr::select(all_of(samples_in_group)))
      
      # Calculate correlations for the current group
      correlations <- cor(cpm_subset, method = "pearson")
      correlation_df <- DESeqDesign %>%
        filter(original_names %in% colnames(correlations))
      
      row.names(correlation_df) <- correlation_df$original_names
      correlation_df <- correlation_df[colnames(correlations), ]
      
      # Create a data frame for the current group
      correlations <- as.data.frame(correlations)
      correlations$original_names <- row.names(correlations)
      cor_distribution <- correlations %>%
        mutate(mean = rowMeans(across(where(is.numeric)))) %>%
        dplyr::select(mean, original_names) %>%
        mutate(treatment = treatment, dose_n = dose_n)
      
      # Add the current group's data to the list
      cor_list_by_group[[paste(treatment, dose_n, sep = "_")]] <-
        cor_distribution
    }
  }
}

if (length(cor_list_by_group) > 0) {
  # Combine the list into a single data frame
  cor_means_by_group <- data.table::rbindlist(cor_list_by_group)
} else {
  cor_means_by_group <- data.frame()
}

# Check if the data frame is empty
if (!exists("cor_means_by_group") ||
    nrow(cor_means_by_group) == 0) {
  message("All groups have only 1 or 2 samples. No correlation plot can be generated.")
} else {
  # Set dynamic lower limit for y-axis
  ymin <- min(cor_means_by_group$mean, na.rm = TRUE)
  
  # Create the plot with dynamic y-axis limits, minimal theme, and meaningful labels
  gg <-
    ggplot(cor_means_by_group, aes(x = interaction(treatment, dose_n), y = mean)) +
    geom_boxplot(outlier.shape = NA) +
    geom_jitter(position = position_jitter(seed = 1, width = 0.2)) +
    geom_text(
      aes(label = original_names),
      position = position_jitter(seed = 1, width = 0.2),
      hjust = 0,
      vjust = 0,
      check_overlap = TRUE
    ) +
    ylim(ymin, 1) +
    ylab(paste0(
      "Mean Pearson Correlation Coefficient by ",
      treatment_var,
      " and ",
      dose_var
    )) +
    xlab(paste(treatment_var, dose_var, sep = " x ")) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
  
  # Save the plot
  ggsave(
    gg,
    file = paste0(
      paths$output,
      "/Samp_for_samp_corr_by_treatment_dose_comparison_boxplot.pdf"
    )
  )
  
  # Print the plot
  print(gg)
}
```

## Reference RNA

This tests the Pearson correlation of log2-normalized CPM of read counts. If your data includes reference RNA, it should be shown here. If your data includes two sources of reference RNA, the same standard mix should shower higher correlations than between different standards. The correlations for the same standards across different batches/plates should be relatively high.

Note-Jory: Our datasets do not contain reference RNA

```{r correlations_7, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=(length(ref_samples) > 0)}
#ref_correlations <- cor(as.matrix(cpm %>%
#                                      dplyr::select(all_of(ref_samples))),
#                          method = "pearson")

#correlation_df <- DESeqDesign %>%
#  filter(original_names %in% colnames(ref_correlations))

#row.names(correlation_df) <- correlation_df$original_names
#correlation_df <- correlation_df[colnames(ref_correlations),]

#correlation_df <- as.data.frame(correlation_df[,unlist(groups[[1]])], drop = FALSE)

#pheatmap(ref_correlations,
#         annotation_col = correlation_df,
#         display_numbers = T,
#         cutree_cols = 2,
#         cutree_rows = 2)

#heatmap_colors <- circlize::colorRamp2(c(0.7, 1), c("blue", "red"))

#annotation_col <- HeatmapAnnotation(df = correlation_df)

# Heatmap(ref_correlations,
#         name = "Correlation",
#         clustering_distance_rows = "pearson",
#         clustering_distance_columns = "pearson",
#         row_km = 2,
#         column_km = 2,
#         cell_fun = function(j, i, x, y, width, height, fill) {
#           grid.text(sprintf("%.2f", ref_correlations[i, j]), x, y, gp = gpar(fontsize = 10))
#           },
#         top_annotation = annotation_col,
#         col = heatmap_colors
#         )

# ref_correlations

```

# {-}

# Compose tables

```{r return_data}


################################################################################
# Add Dendrogram Clustering Pass/Fail to QAQC
################################################################################

# Initialize all samples as "PASS" for dendrogram clustering
QAQC$dendrogram <- "PASS"

# Check if `flag_cluster` exists and update the dendrogram status
if (exists("flag_cluster")) {
  QAQC$dendrogram[QAQC$Sample %in% d$original_names[flag_cluster]] <- "FAIL"
}

# Identify samples that failed the dendrogram clustering
failed_dendro_clustering <- QAQC[QAQC$dendrogram == "FAIL", ]

# Check and print flagged samples
#print("Samples Flagged in Dendrogram Clustering:")
#if (nrow(failed_dendro_clustering) > 0) {
#  print(failed_dendro_clustering$Sample)
#} else {
#  print("No samples failed the dendrogram clustering.")
#}

################################################################################
# Removing Outliers
################################################################################

# Initialize pass/fail for each metric in QAQC
QAQC_pass_fail <- QAQC

# Apply pass/fail criteria for each metric
QAQC_pass_fail <- QAQC_pass_fail %>%
  dplyr::mutate(
    NMR = cut(NMR, c(-Inf, nmr_threshold, Inf), labels = c("FAIL", "PASS"), right = FALSE),
    Ncov5 = cut(Ncov5, 
                 breaks = c(-Inf, percent_active_probes$stats[1, 1] - 0.001, percent_active_probes$stats[5, 1], Inf), 
                 labels = c("FAIL", "PASS", "FAIL"), 
                 right = TRUE),
    Nsig80 = cut(Nsig80, 
                 breaks = c(-Inf, probes_capturing_top_80$stats[1, 1] - 1, probes_capturing_top_80$stats[5, 1], Inf), 
                 labels = c("FAIL", "PASS", "FAIL"), 
                 right = TRUE),
    Gini = cut(Gini, c(-Inf, gini_cutoff, Inf), labels = c("PASS", "FAIL"), right = FALSE),
    pct_mapped = cut(pct_mapped, c(-Inf, align_threshold * 100, Inf), labels = c("FAIL", "PASS"), right = FALSE),
    q30 = cut(q30, c(-Inf, q30_cutoff * 100, Inf), labels = c("FAIL", "PASS"), right = FALSE),
    diff_r1_r2_q30 = cut(diff_r1_r2_q30, c(-Inf, forward_reverse_q30_diff_cutoff * 100, Inf), labels = c("PASS", "FAIL"), right = FALSE),
    PC1_var = cut(PC1_var, c(-Inf, PCA_cutoff * 100, Inf), labels = c("PASS", "FAIL"), right = FALSE),
    PC2_var = cut(PC2_var, c(-Inf, PCA_cutoff * 100, Inf), labels = c("PASS", "FAIL"), right = FALSE)
  )

# Filter rows where any metric has a "FAIL" value
QAQC_failed <- QAQC_pass_fail %>%
  dplyr::rowwise() %>%
  dplyr::filter(any(c_across(everything()) == "FAIL"))

# Convert "FAIL"/"PASS" to 1/0 for easier processing
QAQC_failed_logical <- QAQC_failed %>%
  dplyr::mutate(
    Gini = if_else(Gini == "FAIL", 1, 0),
    Nsig80 = if_else(Nsig80 == "FAIL", 1, 0),
    Ncov5 = if_else(Ncov5 == "FAIL", 1, 0),
    dendrogram = if_else(dendrogram == "FAIL", 1, 0),
    NMR = if_else(NMR == "FAIL", 1, 0),
    pct_mapped = if_else(pct_mapped == "FAIL", 1, 0),
    q30 = if_else(q30 == "FAIL", 1, 0),
    diff_r1_r2_q30 = if_else(diff_r1_r2_q30 == "FAIL", 1, 0),
    PC1_var = if_else(PC1_var == "FAIL", 1, 0),
    PC2_var = if_else(PC2_var == "FAIL", 1, 0)
  )

# Join with metadata to include treatment and dose information
QAQC_failed_logical <- QAQC_failed_logical %>%
  dplyr::left_join(d %>% dplyr::select(original_names, !!sym(treatment_var), !!sym(dose)),
                   by = c("Sample" = "original_names"))

# Ensure numeric conversion for all fail indicators
QAQC_failed_logical <- QAQC_failed_logical %>%
  dplyr::mutate(
    NMR = as.numeric(NMR),
    Ncov5 = as.numeric(Ncov5),
    Nsig80 = as.numeric(Nsig80),
    Gini = as.numeric(Gini),
    dendrogram = as.numeric(dendrogram),
    pct_mapped = as.numeric(pct_mapped),
    q30 = as.numeric(q30),
    diff_r1_r2_q30 = as.numeric(diff_r1_r2_q30),
    PC1_var = as.numeric(PC1_var),
    PC2_var = as.numeric(PC2_var)
  )

print("QC table composed successfully.")
```

# Outliers {.tabset}

This section shows several tables of the outlier data.  

## UpSet plot

This plot shows the various QC metrics that may result in sample removal, along with the numbers of samples that were removed for one or more of those filters.  

If the "UpSet" plot makes you upset, please skip to the much more intuitive "vtree".

```{r upset_plot, out.height='100%', out.width='100%'}
# Prepare data for UpSet plot
upset_data <- QAQC_failed_logical[, c(
  "NMR",
  "dendrogram",
  "Ncov5",
  "Nsig80",
  "Gini",
  "pct_mapped",
  "q30",
  "diff_r1_r2_q30",
  "PC1_var",
  "PC2_var"
)]

# Convert to logical, then to integer for the UpSet plot
upset_data <- upset_data %>%
  dplyr::mutate(across(everything(), as.logical)) %>%
  dplyr::mutate(across(everything(), as.integer))

# Convert the data frame to a list for the UpSet plot
upset_data_list <- as.list(upset_data)

# Check if there are multiple samples that failed, then generate the UpSet plot
if (nrow(QAQC_failed_logical) > 1) {
  png(
    file = file.path(paths$output, "upset_plot.png"),
    units = "in",
    width = 8,
    height = 8,
    res = 300
  )
  print(upset(fromList(upset_data_list)))
  dev.off()
  knitr::include_graphics(file.path(paths$output, "upset_plot.png"))
} else {
  print("No samples failed QC. Skipping upset plot.")
}
```

## Part one - Vtree plot

```{r vtree_plot_1, collapse=TRUE, out.height='100%', out.width='100%'}
# Join DESeqDesign with QAQC_pass_fail and QAQC
QAQC_annotated <- dplyr::left_join(DESeqDesign, QAQC_pass_fail, by = c("original_names" = "Sample")) %>%
  dplyr::right_join(QAQC, by = c("original_names" = "Sample"), suffix = c("", "_data"))

# Create a new column 'Any' to indicate if any metric has failed
QAQC_annotated$Any <- apply(
  QAQC_annotated,
  MARGIN = 1,
  FUN = function(x) ifelse(any(x == "FAIL"), "FAIL", "PASS")
)

# Generate vtree plots
vtree1 <- vtree(
  QAQC_annotated,
  c("dendrogram", "NMR", "Ncov5", "Nsig80", "Gini", "pct_mapped", "q30", "diff_r1_r2_q30", "PC1_var", "PC2_var", "Any"),
  summary = "NMR_data \nAverage Reads Mapped\n%mean% %leafonly% ",
  pngknit = FALSE
)

vtree2 <- vtree(
  QAQC_annotated,
  c("dendrogram", "NMR", "Ncov5", "Nsig80", "Gini", "pct_mapped", "q30", "diff_r1_r2_q30", "PC1_var", "PC2_var"),
  summary = "NMR_data \nAverage Reads Mapped\n%mean% %leafonly% ",
  pattern = TRUE,
  pngknit = FALSE
)

# Save the vtree plots as PNG files
grVizToPNG(vtree1, folder = paths$output, filename = "Vtree_Plot1.png")
grVizToPNG(vtree2, folder = paths$output, filename = "Vtree_Plot2.png")

# Include the vtree plots in the report
include_safe_graphics(file.path(paths$output, "Vtree_Plot1.png"))
```

## Part two - Vtree plot

```{r vtree_plot_2, collapse=TRUE, out.height='100%', out.width='100%'}
include_safe_graphics(file.path(paths$output, "Vtree_Plot2.png"))
```

## Outlier sample names

```{r outlier_sample_names}
# Extract outlier samples from QAQC_failed
outliers <- QAQC_failed$Sample
if (length(outliers) > 0) {print(outliers)} else {print("No outlier samples")}

# Filter metadata for outlier samples
outlier_metadata <- DESeqDesign %>%
  dplyr::filter(original_names %in% outliers)

# Filter metadata for samples with outliers removed
metadata_outliers_removed <- DESeqDesign %>%
  dplyr::filter(!original_names %in% outliers) %>%
  dplyr::filter(!!ensym(technical_control) == FALSE)
```

## Potential covariates

This examines correlations between the QC metrics calculated and any factors in the experimental design.  

Please note that in these pairwise plots, some relationships are meaningless (e.g., dose vs dose). This is meant to explore trends that may not otherwise be apparent.  

```{r possible_covariates, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}


### Come back to this. How on earth can we automate this or make it generic!?
### Add in n vectors... a list of vectors to loop over?
### list(a,b,c) where a is ("row","column") ?
### Common columns - vector of NMR_data, Ncov5_data, Nsig80_data, Gini_data

QAQC_metadata_subset <- QAQC_annotated %>%
  dplyr::select(
    unlist(groups),
    NMR_data,
    Ncov5_data,
    Nsig80_data,
    Gini_data,
    pct_mapped_data,
    q30_data,
    diff_r1_r2_q30_data,
    PC1_var,
    PC2_var
  )

# Summarize levels of each factor variable (checking for potential covariates)
QAQC_metadata_subset %>%
  summarise_each(levels(as.factor(.))) %>% tally()

# Identify potential covariates with fewer than 24 unique levels
potential_covariates <- QAQC_metadata_subset %>%
  dplyr::mutate_all(as.factor) %>%
  purrr::map(levels) %>%
  purrr::map(length)

covariate_names <-
  names(potential_covariates[potential_covariates < 24])

# Need a generic way to look for dose column...
#QAQC_metadata_subset$Dose <- factor(log(QAQC_metadata_subset$Dose+1))

# Generate pairwise plots using ggpairs, colored by the first group in the groups list
for (i in seq_along(covariate_names)) {
  ggpairs(
    QAQC_metadata_subset,
    cardinality_threshold = 24,
    columns = c(
      covariate_names,
      "NMR_data",
      "Ncov5_data",
      "Nsig80_data",
      "Gini_data",
      "pct_mapped_data",
      "q30_data",
      "diff_r1_r2_q30_data",
      "PC1_var",
      "PC2_var"
    ),
    ggplot2::aes(colour = groups[[1]][1])
  )
}

# Generate pairwise plots for each group in the groups list
for (i in seq_along(groups)) {
  group_comparison <- groups[[i]]
  ggpairs(
    QAQC_metadata_subset,
    cardinality_threshold = 24,
    columns = c(
      unlist(group_comparison),
      "NMR_data",
      "Ncov5_data",
      "Nsig80_data",
      "Gini_data",
      "pct_mapped_data",
      "q30_data",
      "diff_r1_r2_q30_data",
      "PC1_var",
      "PC2_var"
    ),
    ggplot2::aes(colour = groups[[1]][1])
  )
}
if (length(groups) > 1 & !is.null(batch_var)) {
  for (i in seq_along(groups)[2:length(groups)]) {
    p <- ggpairs(
      QAQC_metadata_subset,
      cardinality_threshold = 24,
      columns = c(
        unlist(groups[[i]]),
        "NMR_data",
        "Ncov5_data",
        "Nsig80_data",
        "Gini_data",
        "pct_mapped_data",
        "q30_data",
        "diff_r1_r2_q30_data",
        "PC1_var",
        "PC2_var"
      ),
      ggplot2::aes(colour = !!ensym(batch_var))
    )
    print(p)
    ggsave(p, file = paste0(paths$output, "/Potential_covariates_plot.pdf"))
  }
} else {
  if (!is.null(batch_var)) {
    p <- ggpairs(
      QAQC_metadata_subset,
      cardinality_threshold = 24,
      columns = c(
        unlist(groups),
        "NMR_data",
        "Ncov5_data",
        "Nsig80_data",
        "Gini_data",
        "pct_mapped_data",
        "q30_data",
        "diff_r1_r2_q30_data",
        "PC1_var",
        "PC2_var"
      ),
      ggplot2::aes(colour = !!ensym(batch_var))
    )
    print(p)
    ggsave(p, file = paste0(paths$output, "/Potential_covariates_plot.pdf"))
  } else {
    if (is.null(batch_var)) {
      p <- ggpairs(
        QAQC_metadata_subset,
        cardinality_threshold = 24,
        columns = c(
          unlist(groups),
          "NMR_data",
          "Ncov5_data",
          "Nsig80_data",
          "Gini_data",
          "pct_mapped_data",
          "q30_data",
          "diff_r1_r2_q30_data",
          "PC1_var",
          "PC2_var"
        )
      )
      print(p)
      ggsave(p,
             file = paste0(paths$output, "/Potential_covariates_plot.pdf"))
    }
  }
}

#knitr::include_graphics(paste0(paths$output, "/Potential_covariates_plot.pdf"))

```

## Plate position effects

```{r plate_pos, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval = any(grepl("column", colnames(QAQC_annotated), ignore.case = T))}
#Evaluate if you have plate positions in metadata

ggplatemappedreads <- ggplot(QAQC_annotated, aes(x = factor(column),
                                                 y = factor(row, levels = rev(levels(
                                                   factor(row)
                                                 ))))) +
  geom_tile(mapping = aes(fill = log(Dose + 1)), data = QAQC_annotated) +
  scale_fill_gradient(low = "grey", high = "black") +
  geom_point(mapping = aes(color = NMR_data),
             data = QAQC_annotated,
             size = 3) +
  scale_x_discrete(position = "top") +
  coord_fixed() +
  #There are no batch vars for the downloaded datasets... OR are there!?
  #facet_wrap(paste0("~",batch_var)) +
  ggtitle("Number of mapped reads") +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )

ggplatensig80 <- ggplot(QAQC_annotated, aes(x = factor(column),
                                            y = factor(row, levels = rev(levels(
                                              factor(row)
                                            ))))) +
  geom_tile(mapping = aes(fill = log(Dose + 1)), data = QAQC_annotated) +
  scale_fill_gradient(low = "grey", high = "black") +
  geom_point(
    mapping = aes(color = Nsig80_data),
    data = QAQC_annotated,
    size = 3
  ) +
  scale_x_discrete(position = "top") +
  coord_fixed() +
  #There are no batch vars for the downloaded datasets... OR are there!?
  #facet_wrap(paste0("~",batch_var)) +
  ggtitle("Nsig80") +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )

ggplatencov5 <- ggplot(QAQC_annotated, aes(x = factor(column),
                                           y = factor(row, levels = rev(levels(
                                             factor(row)
                                           ))))) +
  geom_tile(mapping = aes(fill = log(Dose + 1)), data = QAQC_annotated) +
  scale_fill_gradient(low = "grey", high = "black") +
  geom_point(mapping = aes(color = Ncov5_data),
             data = QAQC_annotated,
             size = 3) +
  scale_x_discrete(position = "top") +
  coord_fixed() +
  #There are no batch vars for the downloaded datasets... OR are there!?
  #facet_wrap(paste0("~",batch_var)) +
  ggtitle("Ncov5") +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )

ggplategini <- ggplot(QAQC_annotated, aes(x = factor(column),
                                          y = factor(row, levels = rev(levels(
                                            factor(row)
                                          ))))) +
  geom_tile(mapping = aes(fill = log(Dose + 1)), data = QAQC_annotated) +
  scale_fill_gradient(low = "grey", high = "black") +
  geom_point(mapping = aes(color = Gini_data),
             data = QAQC_annotated,
             size = 3) +
  scale_x_discrete(position = "top") +
  coord_fixed() +
  #There are no batch vars for the downloaded datasets... OR are there!?
  #facet_wrap(paste0("~",batch_var)) +
  ggtitle("Gini") +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )

ggplatefailed <- ggplot(QAQC_annotated, aes(x = factor(column),
                                            y = factor(row, levels = rev(levels(
                                              factor(row)
                                            ))))) +
  geom_tile(mapping = aes(fill = log(Dose + 1)), data = QAQC_annotated) +
  scale_fill_gradient(low = "grey", high = "black") +
  geom_point(mapping = aes(color = Any),
             data = QAQC_annotated,
             size = 3) +
  scale_x_discrete(position = "top") +
  coord_fixed() +
  #There are no batch vars for the downloaded datasets... OR are there!?
  #facet_wrap(paste0("~",batch_var)) +
  ggtitle("Any samples failed") +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.title.x = element_blank(),
    axis.title.y = element_blank()
  )

ggsave(ggplatemappedreads,
       file = paste0(paths$output, "/PlatePosition_Mapped_reads_plot.pdf"))
ggsave(ggplatensig80,
       file = paste0(paths$output, "/PlatePosition_NSig80_plot.pdf"))
ggsave(ggplatencov5,
       file = paste0(paths$output, "/PlatePosition_NCov5_plot.pdf"))
ggsave(ggplategini,
       file = paste0(paths$output, "/PlatePosition_Gini_plot.pdf"))
ggsave(
  ggpplatefailed,
  file = paste0(
    paths$output,
    "/PlatePosition_Samples_failing_filters_plot.pdf"
  )
)

print(ggplatemappedreads)
print(ggplatensig80)
print(ggplatencov5)
print(ggplategini)
print(ggpplatefailed)
#knitr::include_graphics(paste0(paths$output, "/PlatePosition_Mapped_reads_plot.pdf"))
#knitr::include_graphics(paste0(paths$output, "/PlatePosition_NSig80_plot.pdf"))
#knitr::include_graphics(paste0(paths$output, "/PlatePosition_NCov5_plot.pdf"))
#knitr::include_graphics(paste0(paths$output, "/PlatePosition_Gini_plot.pdf"))
#knitr::include_graphics(paste0(paths$output, "/PlatePosition_Samples_failing_filters_plot.pdf"))
```


## Metadata of samples identified as outliers

```{r table_metadata}


knitr::kable(outlier_metadata,
             caption = "Samples Removed") %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = F,
    position = "left"
  ) %>%
  kableExtra::scroll_box(width = "100%", height = "480px")

QAQC_failed_kable <- outlier_metadata %>%
  dplyr::select(original_names,!!ensym(treatment_var)) %>%
  left_join(QAQC_failed, by = (c("original_names" = "Sample")))

```

## Pass/fail table for samples identified as outliers

```{r table_pass_fail}


knitr::kable(QAQC_failed_kable,
             caption = "Which samples were removed and why?") %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = F,
    position = "left"
  ) %>%
  scroll_box(width = "100%", height = "480px")


```

## Summary of pass/fail for each test

```{r pass_fail_summary}
#QAQC_annotated %>%
#  dplyr::group_by(dendrogram, NMR, Ncov5, Nsig80, Gini, pct_mapped, q30, diff_r1_r2_q30, PC1_var, PC2_var, Any) %>%
#  tally()

QAQC_annotated %>%
  dplyr::group_by(
    dendrogram,
    NMR,
    Ncov5,
    Nsig80,
    Gini,
    pct_mapped,
    q30,
    diff_r1_r2_q30,
    PC1_var,
    PC2_var,
    Any
  ) %>%
  tally() %>%
  knitr::kable(caption = "Summary of pass/fail results") %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = F,
    position = "left"
  ) %>%
  scroll_box(width = "100%", height = "480px")
```

## Pass/fail for each test, broken up by sample groups

```{r pass_fail_by_group}
#QAQC_annotated %>%
#  dplyr::group_by(dendrogram, NMR, Ncov5, Nsig80, Gini, pct_mapped, q30, diff_r1_r2_q30, PC1_var, PC2_var, Any, across(all_of(unlist(groups)))) %>%
#  tally()

QAQC_annotated %>%
  dplyr::group_by(
    dendrogram,
    NMR,
    Ncov5,
    Nsig80,
    Gini,
    pct_mapped,
    q30,
    diff_r1_r2_q30,
    PC1_var,
    PC2_var,
    Any,
    across(all_of(unlist(groups)))
  ) %>%
  tally() %>%
  knitr::kable(caption = "Pass/fail results by group") %>%
  kable_styling(
    bootstrap_options = "striped",
    full_width = F,
    position = "left"
  ) %>%
  scroll_box(width = "100%", height = "480px")
```

## Write tables to disk

```{r write_output}


outlier_metadata_annotated <- dplyr::left_join(outlier_metadata,
                                               QAQC_pass_fail,
                                               by = c("original_names" = "Sample"))
write.table(
  outlier_metadata_annotated,
  normalizePath(file.path(paths$output, "samples_removed.txt")),
  sep = "\t",
  row.names = FALSE,
  col.names = TRUE,
  quote = FALSE
)

write.table(
  QAQC_annotated,
  normalizePath(file.path(paths$output, "QC_per_sample.txt")),
  sep = "\t",
  row.names = FALSE,
  col.names = TRUE,
  quote = FALSE
)

write.table(
  metadata_outliers_removed,
  normalizePath(file.path(paths$output, "metadata.QC_applied.txt")),
  sep = "\t",
  row.names = FALSE,
  col.names = TRUE,
  quote = FALSE
)

sampleData_filtered <-
  sampleData %>% dplyr::select(-all_of(outliers))
print(paste(
  "Writing sample data for",
  ncol(sampleData_filtered),
  "filtered samples"
))
```

# Post-QC and data exploration {.tabset}

## Dendrogram, all samples, postfiltering

```{r dendrogram_all_after, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
############################################################################
# Dendrogram: all, after filtering
############################################################################

CairoPDF(
  file = normalizePath(file.path(
    paths$output, "dendrogram_postfiltering_all.pdf"
  )),
  width = 14,
  height = 8.5,
  pointsize = 12,
  family = "Ubuntu"
)

dendro_after_all_samples <-
  1 - cor(as.matrix(cpm %>% dplyr::select(-all_of(outliers))),
          method = "spearman")

if (dim(dendro_after_all_samples)[1] < 2) {
  print("Not enough samples left after filtering to create a dendrogram")
} else {
  dendro_after_all_samples <-
  sort_hclust(hclust(as.dist(dendro_after_all_samples), method = "average"))

  dendro_after_all_samples <- as.dendrogram(dendro_after_all_samples)
  colors_to_use <-
    as.numeric(as.factor(DESeqDesign[, technical_control]))
  ordered_colors <-
    colors_to_use[order.dendrogram(dendro_after_all_samples)]
  labels_colors(dendro_after_all_samples) <- ordered_colors

  original_names <- DESeqDesign[, "original_names"]
  original_names <-
    original_names[order.dendrogram(dendro_after_all_samples)]

  labels_to_use <- DESeqDesign[, dendro_color_by]
  labels_to_use <-
    labels_to_use[order.dendrogram(dendro_after_all_samples)]
  labels_to_use <- paste(labels_to_use, original_names)

  #par(cex = 0.15, mar = c(15, 4, 4, 2))
  plot(
    dendro_after_all_samples %>% dendextend::set("labels", labels_to_use),
    main = "log2 CPM",
    horiz = F
  )
  abline(h = tree_height_cutoff, col = "red", lwd = 2)
  dev.off()
}
```

## Dendrogram, technical control samples, postfiltering

```{r dendrogram_technical_after, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
############################################################################
# Technical Controls, Postfiltering
############################################################################
dendro_after_tech_ctrls <- 1 - cor(as.matrix(cpm %>%
                                               dplyr::select(all_of(tech_ctrl_names)) %>%
                                               dplyr::select(-all_of(outliers[outliers %in% tech_ctrl_names]))),
                                   method = "spearman")
if (dim(dendro_after_tech_ctrls)[1] > 2) {
  DESeqDesignTechCtrls <-
    DESeqDesign %>% dplyr::filter(original_names %in% all_of(tech_ctrl_names))
  
  dendro_after_tech_ctrls <-
    sort_hclust(hclust(as.dist(dendro_after_tech_ctrls), method = "average"))
  
  dendro_after_tech_ctrls <- as.dendrogram(dendro_after_tech_ctrls)
  colors_to_use <-
    as.numeric(as.factor(DESeqDesignTechCtrls[, dendro_color_by]))
  ordered_colors <-
    colors_to_use[order.dendrogram(dendro_after_tech_ctrls)]
  labels_colors(dendro_after_tech_ctrls) <- ordered_colors
  
  original_names <- DESeqDesignTechCtrls[, "original_names"]
  original_names <-
    original_names[order.dendrogram(dendro_after_tech_ctrls)]
  
  labels_to_use <- DESeqDesignTechCtrls[, dendro_color_by]
  labels_to_use <-
    labels_to_use[order.dendrogram(dendro_after_tech_ctrls)]
  labels_to_use <- paste(labels_to_use, original_names)
  
  CairoPDF(
    file = normalizePath(
      file.path(
        paths$output,
        "dendrogram_postfiltering_tech_controls.pdf"
      )
    ),
    width = 14,
    height = 8.5,
    family = "Ubuntu"
  )
  #par(cex = 0.4, mar = c(15, 4, 4, 2))
  plot(
    dendro_after_tech_ctrls %>% dendextend::set("labels", labels_to_use),
    main = "log2 CPM",
    horiz = F
  )
  abline(h = tree_height_cutoff, col = "red", lwd = 2)
  dev.off()

  include_safe_graphics(file.path(paths$output, "dendrogram_postfiltering_tech_controls.pdf"))
} else {
  print("Not enough samples left after filtering to create the dendrogram")
}


```

## Dendrogram, experimental samples, postfiltering

```{r dendrogram_exp_after, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
############################################################################
# Experimental Samples, Postfiltering
############################################################################

CairoPDF(
  file = normalizePath(
    file.path(paths$output,
              "dendrogram_postfiltering_exp_samples.pdf")
  ),
  width = 14,
  height = 8.5,
  family = "Ubuntu"
)

dendro_after_all_exp_samples <- 1 - cor(as.matrix(cpm %>%
                                                    dplyr::select(all_of(sample_names)) %>%
                                                    dplyr::select(-all_of(outliers[outliers %in% sample_names]))),
                                        method = "spearman")

if (dim(dendro_after_all_exp_samples)[1] < 2) {
  print("Not enough samples left after filtering to create a dendrogram")
} else {
  DESeqDesignExpSamples <-
    DESeqDesign %>% dplyr::filter(original_names %in% all_of(sample_names))

  dendro_after_all_exp_samples <-
    sort_hclust(hclust(as.dist(dendro_after_all_exp_samples), method = "average"))

  dendro_after_all_exp_samples <-
    as.dendrogram(dendro_after_all_exp_samples)
  colors_to_use <-
    as.numeric(as.factor(DESeqDesignExpSamples[, unlist(groups)[1]]))
  ordered_colors <-
    colors_to_use[order.dendrogram(dendro_after_all_exp_samples)]
  labels_colors(dendro_after_all_exp_samples) <- ordered_colors

  original_names <- DESeqDesignExpSamples[, "original_names"]
  original_names <-
    original_names[order.dendrogram(dendro_after_all_exp_samples)]

  labels_to_use <- DESeqDesignExpSamples[, dendro_color_by]
  labels_to_use <-
    labels_to_use[order.dendrogram(dendro_after_all_exp_samples)]
  labels_to_use <- paste(labels_to_use, original_names)

  #par(cex = 0.2, mar = c(15, 4, 4, 2))
  plot(
    dendro_after_all_exp_samples %>% dendextend::set("labels", labels_to_use),
    main = "log2 CPM",
    horiz = F
  )
  abline(h = tree_height_cutoff, col = "red", lwd = 2)
  dev.off()
}
```

## Dendrogram, experimental samples, postfiltering, colored by dose

```{r dendrogram_exp_post_dose, echo = FALSE, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%'}
############################################################################
# Experimental Samples, Postfiltering, Colored by Dose
############################################################################

CairoPDF(
  file = normalizePath(
    file.path(
      paths$output,
      "dendrogram_postfiltering_exp_samples_by_dose.pdf"
    )
  ),
  width = 14,
  height = 8.5,
  family = "Ubuntu"
)

# Calculate the dendrogram
dendro_after_all_exp_samples <- 1 - cor(as.matrix(cpm %>%
                                                    dplyr::select(all_of(sample_names)) %>%
                                                    dplyr::select(-all_of(outliers[outliers %in% sample_names]))),
                                        method = "spearman")

if (dim(dendro_after_all_exp_samples)[1] < 2) {
  print("Not enough samples left after filtering to create a dendgrogram")
} else {
  DESeqDesignExpSamples <-
  DESeqDesign %>% dplyr::filter(original_names %in% all_of(sample_names))

  dendro_after_all_exp_samples <-
    sort_hclust(hclust(as.dist(dendro_after_all_exp_samples), method = "average"))

  dendro_after_all_exp_samples <-
    as.dendrogram(dendro_after_all_exp_samples)
  colors_to_use <-
    as.numeric(as.factor(DESeqDesignExpSamples[, dendro_color_by]))
  ordered_colors <-
    colors_to_use[order.dendrogram(dendro_after_all_exp_samples)]
  labels_colors(dendro_after_all_exp_samples) <- ordered_colors

  original_names <- DESeqDesignExpSamples[, "original_names"]
  original_names <-
    original_names[order.dendrogram(dendro_after_all_exp_samples)]

  labels_to_use <- DESeqDesignExpSamples[, dendro_color_by]
  labels_to_use <-
    labels_to_use[order.dendrogram(dendro_after_all_exp_samples)]
  labels_to_use <- paste(labels_to_use, original_names)

  # Plot the dendrogram
  plot(
    dendro_after_all_exp_samples %>% dendextend::set("labels", labels_to_use),
    main = "log2 CPM",
    horiz = F
  )
  abline(h = tree_height_cutoff, col = "red", lwd = 2)

  # Create the legend
  unique_labels <- unique(DESeqDesignExpSamples[, dendro_color_by])
  unique_colors <- unique(colors_to_use)

  legend("topright",
         legend = unique_labels,
         fill = unique_colors,
         title = dendro_color_by)

  dev.off()
}
```

# {-}

## Potential batch effects

Only applicable if a batch variable is present in metadata.

```{r plot_batch_effects, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval = !is.null(batch_var)}
ggbatchgini <-
  ggplot(QAQC_annotated, aes(x = batch_var, color = treatment_var)) +
  geom_boxplot(aes(y = Gini_data)) +
  facet_grid(paste0("~", batch_var), scales = "free_x") +
  ggtitle("Gini") +
  theme(legend.position = "bottom")

ggbatchNMR <-
  ggplot(QAQC_annotated, aes(x = batch_var, color = treatment_var)) +
  geom_boxplot(aes(y = NMR_data)) +
  facet_grid(paste0("~", batch_var), scales = "free_x") +
  ggtitle("Number of Mapped Reads") +
  theme(legend.position = "bottom")

ggbatchNCov5 <-
  ggplot(QAQC_annotated, aes(x = batch_var, color = treatment_var)) +
  geom_boxplot(aes(y = Ncov5_data)) +
  facet_grid(paste0("~", batch_var), scales = "free_x") +
  ggtitle("Proportion of active probes (% probes with >5 mapped reads)") +
  theme(legend.position = "bottom")

ggbatchNSig80 <-
  ggplot(QAQC_annotated, aes(x = batch_var, color = treatment_var)) +
  geom_boxplot(aes(y = Nsig80_data)) +
  facet_grid(paste0("~", batch_var), scales = "free_x") +
  ggtitle("Proportion of probes required to account for 80% of signal") +
  theme(legend.position = "bottom")

ggsave(ggbatchgini,
       file = paste0(paths$output, "/Batch_Effects_Gini_plot.pdf"))
ggsave(ggbatchNMR,
       file = paste0(paths$output, "/Batch_Effects_Mapped_reads_plot.pdf"))
ggsave(ggbatchNCov5,
       file = paste0(paths$output, "/Batch_Effects_NCov5_plot.pdf"))
ggsave(ggbatchNSig80,
       file = paste0(paths$output, "/Batch_Effects_NSig80_plot.pdf"))


print(ggbatchNMR)
print(ggbatchNCov5)
print(ggbatchNSig80)
print(ggbatchgini)
```

## Sample filters by dose {.tabset}

```{r plot_chemical_differences, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
#dendrogram, pct_mapped, q30, diff_r1_r2_q30, PC1_var, PC2_var
ggdosegini <-
  ggplot(QAQC_annotated, aes(x = !!ensym(treatment_var), y = Gini_data)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge(width = 0.75)) +  # Remove outlier points from the boxplot itself
  geom_jitter(
    aes(fill = factor(!!ensym(dose))),
    shape = 21,
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    )
  ) +  # Add jittered points with fill color by dose, clustered by dose group
  geom_hline(yintercept = gini_cutoff,
             linetype = "dotted",
             color = "red") +  # Add the Gini threshold line at 0.95
  geom_text(
    data = QAQC_annotated %>% filter(Gini == "FAIL"),
    # Filter for samples marked as FAIL
    aes(label = original_names, fill = factor(!!ensym(dose))),
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    ),
    hjust = -0.2,
    vjust = 0,
    check_overlap = TRUE,
    size = 3,
    color = "red"
  ) +  # Add sample names next to outlier points
  ylim(min(QAQC_annotated$Gini_data, na.rm = TRUE), 1) +  # Set dynamic lower limit and upper limit to 1
  ylab("Gini Coefficient") +  # Label for y-axis
  xlab(as.character(treatment_var)) +  # Label for x-axis using the treatment variable name
  theme_minimal() +  # Apply minimal theme
  ggtitle("Gini") +
  scale_fill_discrete(name = as.character(dose))  # Adjust legend title for fill

ggdosenmr <-
  ggplot(dplyr::group_by(QAQC_annotated,!!ensym(dose)),
         aes(x = !!ensym(treatment_var), y = NMR_data)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge(width = 0.75)) +  # Remove outlier points and dodge by dose group
  geom_jitter(
    aes(fill = factor(!!ensym(dose))),
    shape = 21,
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    )
  ) +  # Jittered points with fill color by dose, clustered by dose group
  geom_hline(yintercept = nmr_threshold,
             linetype = "dotted",
             color = "red") +  # Add the threshold line for NMR data
  geom_text(
    data = QAQC_annotated %>% filter(NMR == "FAIL"),
    # Filter for samples below the threshold
    aes(label = original_names, fill = factor(!!ensym(dose))),
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    ),
    hjust = -0.2,
    vjust = 0,
    check_overlap = TRUE,
    color = "red",
    size = 3
  ) +  # Add sample names next to points below the threshold
  ylim(0, max(QAQC_annotated$NMR_data, na.rm = TRUE)) +  # Set the y-axis with a lower limit of 0 and dynamic upper limit
  ylab("Number of Mapped Reads") +  # Label for y-axis
  xlab(as.character(treatment_var)) +  # Label for x-axis using the treatment variable name
  theme_minimal() +  # Apply minimal theme
  ggtitle("Total Mapped Reads") +
  scale_fill_discrete(name = as.character(dose))  # Adjust legend title for fill

ggdosencov5 <-
  ggplot(dplyr::group_by(QAQC_annotated,!!ensym(dose)),
         aes(x = !!ensym(treatment_var), y = Ncov5_data)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge(width = 0.75), coef = 3) +  # Remove outlier points and dodge by dose group, and make whiskers extend to 3XIQR
  geom_jitter(
    aes(fill = factor(!!ensym(dose))),
    shape = 21,
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    )
  ) +  # Jittered points with fill color by dose, clustered by dose group
  geom_text(
    data = QAQC_annotated %>% filter(Ncov5 == "FAIL"),
    # Filter for samples marked as FAIL
    aes(label = original_names, fill = factor(!!ensym(dose))),
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    ),
    hjust = -0.2,
    vjust = 0,
    check_overlap = TRUE,
    color = "red",
    size = 3
  ) +  # Add sample names next to points marked as FAIL
  ylim(
    min(QAQC_annotated$Ncov5_data, na.rm = TRUE) - 0.01,
    max(QAQC_annotated$Ncov5_data, na.rm = TRUE) + 0.01
  ) +  # Set the y-axis with a dynamic lower limit and upper limit
  ylab("Proportion of Active Probes (% probes with >5 mapped reads)") +  # Label for y-axis
  xlab(as.character(treatment_var)) +  # Label for x-axis using the treatment variable name
  theme_minimal() +  # Apply minimal theme
  ggtitle("NCov5") +
  scale_fill_discrete(name = as.character(dose))  # Adjust legend title for fill

ggdosensig80 <-
  ggplot(dplyr::group_by(QAQC_annotated,!!ensym(dose)),
         aes(x = !!ensym(treatment_var), y = Nsig80_data)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge(width = 0.75), coef = 3) +  # Remove outlier points and dodge by dose group
  geom_jitter(
    aes(fill = factor(!!ensym(dose))),
    shape = 21,
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    )
  ) +  # Jittered points with fill color by dose, clustered by dose group
  geom_text(
    data = QAQC_annotated %>% filter(Nsig80 == "FAIL"),
    # Filter for samples marked as FAIL
    aes(label = original_names, fill = factor(!!ensym(dose))),
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    ),
    hjust = -0.2,
    vjust = 0,
    check_overlap = TRUE,
    color = "red",
    size = 3
  ) +  # Add sample names next to points marked as FAIL
  ylim(
    min(QAQC_annotated$Nsig80_data, na.rm = TRUE) - 10,
    max(QAQC_annotated$Nsig80_data, na.rm = TRUE) + 10
  ) +  # Set the y-axis with a dynamic lower limit and upper limit
  ylab("Probes Required to Account for 80% of Signal") +  # Label for y-axis
  xlab(as.character(treatment_var)) +  # Label for x-axis using the treatment variable name
  theme_minimal() +  # Apply minimal theme
  ggtitle("NSig80") +
  scale_fill_discrete(name = as.character(dose))  # Adjust legend title for fill

# Q30 Plot
ggdoseq30 <-
  ggplot(dplyr::group_by(QAQC_annotated,!!ensym(dose)),
         aes(x = !!ensym(treatment_var), y = q30_data)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge(width = 0.75)) +  # Dodge boxplots by dose group
  geom_jitter(
    aes(fill = factor(!!ensym(dose))),
    shape = 21,
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    )
  ) +  # Jitter points by dose
  geom_hline(yintercept = q30_cutoff * 100,
             linetype = "dotted",
             color = "red") +  # Add threshold line
  geom_text(
    data = QAQC_annotated %>% filter(q30 == "FAIL"),
    # Filter for samples below the Q30 threshold
    aes(label = original_names, fill = factor(!!ensym(dose))),
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    ),
    hjust = -0.2,
    vjust = 0,
    check_overlap = TRUE,
    color = "red",
    size = 3
  ) +  # Add sample names next to points below the threshold
  ylim(if_else(condition = min(QAQC_annotated$q30_data, na.rm = TRUE) < (q30_cutoff * 100), true = min(QAQC_annotated$q30_data, na.rm = TRUE) - 1, false = (q30_cutoff * 100) - 1), 100) +  # Dynamic y-axis from 0 to max value
  ylab("Q30 Percentage") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("Q30 percentage") +
  scale_fill_discrete(name = as.character(dose))  # Legend title

# Difference in Q30 Between R1 and R2 Plot
ggdoseq30diff <-
  ggplot(dplyr::group_by(QAQC_annotated,!!ensym(dose)),
         aes(x = !!ensym(treatment_var), y = diff_r1_r2_q30_data)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge(width = 0.75)) +  # Dodge boxplots by dose group
  geom_jitter(
    aes(fill = factor(!!ensym(dose))),
    shape = 21,
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    )
  ) +  # Jitter points by dose
  geom_hline(yintercept = forward_reverse_q30_diff_cutoff * 100,
             linetype = "dotted",
             color = "red") +  # Add threshold line
  geom_text(
    data = QAQC_annotated %>% filter(diff_r1_r2_q30 == "FAIL"),
    # Filter for samples below the Q30 difference threshold
    aes(label = original_names, fill = factor(!!ensym(dose))),
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    ),
    hjust = -0.2,
    vjust = 0,
    check_overlap = TRUE,
    color = "red",
    size = 3
  ) +  # Add sample names next to points below the threshold
  ylim(
    0,
    if_else(
      condition = max(QAQC_annotated$diff_r1_r2_q30_data, na.rm = TRUE) > forward_reverse_q30_diff_cutoff * 100,
      true = max(QAQC_annotated$diff_r1_r2_q30_data, na.rm = TRUE) + 1,
      false = (forward_reverse_q30_diff_cutoff * 100) + 1
    )
  ) +  # Dynamic y-axis from 0 to max value
  ylab("Difference in Q30 Between R1 and R2") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("Difference in Q30 Between R1 and R2") +
  scale_fill_discrete(name = as.character(dose))  # Legend title

# Percentage of Mapped Reads Plot
ggdosepctmapped <-
  ggplot(dplyr::group_by(QAQC_annotated,!!ensym(dose)),
         aes(x = !!ensym(treatment_var), y = pct_mapped_data)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge(width = 0.75)) +  # Dodge boxplots by dose group
  geom_jitter(
    aes(fill = factor(!!ensym(dose))),
    shape = 21,
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    )
  ) +  # Jitter points by dose
  geom_hline(yintercept = align_threshold * 100,
             linetype = "dotted",
             color = "red") +  # Add threshold line at 70%
  geom_text(
    data = QAQC_annotated %>% filter(pct_mapped == "FAIL"),
    # Filter for samples below the percentage mapped threshold
    aes(label = original_names, fill = factor(!!ensym(dose))),
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    ),
    hjust = -0.2,
    vjust = 0,
    check_overlap = TRUE,
    color = "red",
    size = 3
  ) +  # Add sample names next to points below the threshold
  ylim(if_else(
    condition = min(QAQC_annotated$pct_mapped_data, na.rm = TRUE) < align_threshold * 100,
    true = min(QAQC_annotated$pct_mapped_data, na.rm = TRUE),
    false = (align_threshold * 100) - 1
  ),
  100) +  # Dynamic y-axis from 0 to max value
  ylab("Percentage of Mapped Reads") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("% Mapped") +
  scale_fill_discrete(name = as.character(dose))  # Legend title

# PC1 Variance Plot
ggdosepc1var <-
  ggplot(dplyr::group_by(QAQC_annotated,!!ensym(dose)),
         aes(x = !!ensym(treatment_var), y = PC1_var_data)) +
  geom_boxplot(outlier.shape = NA, position = position_dodge(width = 0.75)) +  # Dodge boxplots by dose group
  geom_jitter(
    aes(fill = factor(!!ensym(dose))),
    shape = 21,
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    )
  ) +  # Jitter points by dose
  geom_hline(yintercept = PCA_cutoff * 100,
             linetype = "dotted",
             color = "red") +  # Add threshold line at 20%
  geom_text(
    data = QAQC_annotated %>% filter(PC1_var == "FAIL"),
    # Filter for samples below the PC1 variance threshold
    aes(label = original_names, fill = factor(!!ensym(dose))),
    position = position_jitterdodge(
      jitter.width = 0.2,
      dodge.width = 0.75,
      seed = 1
    ),
    hjust = -0.2,
    vjust = 0,
    check_overlap = TRUE,
    color = "red",
    size = 3
  ) +  # Add sample names next to points below the threshold
  ylim(0, max(QAQC_annotated$PC1_var_data, na.rm = TRUE)) +  # Dynamic y-axis from 0 to max value
  ylab("PC1 Variance") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("Variance of PC1 Across Samples\nRelative to Median in Dose Groups by Treatment") +
  scale_fill_discrete(name = as.character(dose))  # Legend title

ggsave(ggdosegini,
       file = paste0(paths$output, "/Dose_Effects_Gini_plot.pdf"))
ggsave(ggdosenmr,
       file = paste0(paths$output, "/Dose_Effects_Mapped_reads_plot.pdf"))
ggsave(ggdosencov5,
       file = paste0(paths$output, "/Dose_Effects_NCov5_plot.pdf"))
ggsave(ggdosensig80,
       file = paste0(paths$output, "/Dose_Effects_NSig80_plot.pdf"))
ggsave(ggdoseq30, file = paste0(paths$output, "/Dose_Effects_Q30_plot.pdf"))
ggsave(ggdoseq30diff,
       file = paste0(paths$output, "/Dose_Effects_DiffQ30_plot.pdf"))
ggsave(ggdosepctmapped,
       file = paste0(paths$output, "/Dose_Effects_Pct_Mapped_plot.pdf"))
ggsave(ggdosepc1var,
       file = paste0(paths$output, "/Dose_Effects_PC1_plot.pdf"))
```

### Q30 Scores

```{r plot_chemical_differences_Q30, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggdoseq30)
```

### Difference in Q30 scores between paired reads

```{r plot_chemical_differences_Q30_diff, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggdoseq30diff)
```

### Percentage of reads mapping

```{r plot_chemical_differences_pct_mapping, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggdosepctmapped)
```

### Total number of reads mapping

```{r plot_chemical_differences_NMR, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggdosenmr)
```

### PC1 variance

```{plot_chemical_differences_NMR, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggdosepc1var)
```

### Ncov5

```{r plot_chemical_differences_Ncov5, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggdosencov5)
```

### Nsig80

```{r plot_chemical_differences_Nsig80, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggdosensig80)
```

### Gini coefficient

```{r plot_chemical_differences_Gini, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggdosegini)
```

## {-}

## Outliers removed QC metrics {.tabset}

```{r plot_filter_criteria, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=T}
ggq30 <-
  ggplot(dplyr::filter(QAQC_annotated, is.na(Any) |
                         Any != "FAIL"),
         aes(x = !!ensym(treatment_var), y = q30_data)) +
  geom_boxplot(outlier.shape = NA) +  # Remove outlier points from the boxplot itself
  geom_jitter(
    shape = 21,
    fill = "blue",
    position = position_jitter(width = 0.2, seed = 1)
  ) +  # Jittered points with consistent fill color
  geom_hline(yintercept = q30_cutoff * 100,
             linetype = "dotted",
             color = "red") +  # Add threshold line at q30_cutoff
  ylim((q30_cutoff * 100) - 1, 100) +  # Dynamic y-axis from 0 to max value
  ylab("Q30 Percentage") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("Q30 Data by Treatment")

ggq30diff <-
  ggplot(
    dplyr::filter(QAQC_annotated, is.na(Any) |
                    Any != "FAIL"),
    aes(x = !!ensym(treatment_var), y = diff_r1_r2_q30_data)
  ) +
  geom_boxplot(outlier.shape = NA) +  # Remove outlier points from the boxplot itself
  geom_jitter(
    shape = 21,
    fill = "blue",
    position = position_jitter(width = 0.2, seed = 1)
  ) +  # Jittered points with consistent fill color
  #geom_hline(yintercept = forward_reverse_q30_diff_cutoff*100, linetype = "dotted", color = "red") +  # Add threshold line at forward_reverse_q30_diff_cutoff
   ylim(
    0,
    if_else(
      condition = max(QAQC_annotated$diff_r1_r2_q30_data, na.rm = TRUE) > forward_reverse_q30_diff_cutoff * 100,
      true = max(QAQC_annotated$diff_r1_r2_q30_data, na.rm = TRUE) + 1,
      false = (forward_reverse_q30_diff_cutoff * 100) + 1
    )
  ) +  # Dynamic y-axis from 0 to max value asdfasdgasdgsaDGASD
  ylab("Difference in Q30 Between R1 and R2") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("Difference in Q30 Between R1 and R2 by Treatment")

ggpctmapped <-
  ggplot(
    dplyr::filter(QAQC_annotated, is.na(Any) |
                    Any != "FAIL"),
    aes(x = !!ensym(treatment_var), y = pct_mapped_data)
  ) +
  geom_boxplot(outlier.shape = NA) +  # Remove outlier points from the boxplot itself
  geom_jitter(
    shape = 21,
    fill = "blue",
    position = position_jitter(width = 0.2, seed = 1)
  ) +  # Jittered points with consistent fill color
  geom_hline(yintercept = align_threshold * 100,
             linetype = "dotted",
             color = "red") +  # Add threshold line at 70%
  ylim((align_threshold * 100) - 1, 100) +  # Dynamic y-axis from 0 to max value
  ylab("Percentage of Mapped Reads") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("Percentage of Mapped Reads by Treatment")

ggpc1var <-
  ggplot(
    dplyr::filter(QAQC_annotated, is.na(Any) |
                    Any != "FAIL"),
    aes(x = !!ensym(treatment_var), y = PC1_var_data)
  ) +
  geom_boxplot(outlier.shape = NA) +  # Remove outlier points from the boxplot itself
  geom_jitter(
    shape = 21,
    fill = "blue",
    position = position_jitter(width = 0.2, seed = 1)
  ) +  # Jittered points with consistent fill color
  ylim(0 - 1, max(QAQC_annotated$PC1_var_data, na.rm = TRUE) + 1) +  # Dynamic y-axis from 0 to max value
  ylab("PC1 Variance") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("Variance of PC1 Across Samples\nRelative to Median in Dose Groups by Treatment")

gggini <-
  ggplot(dplyr::filter(QAQC_annotated, is.na(Any) |
                         Any != "FAIL"),
         aes(x = !!ensym(treatment_var), y = Gini_data)) +
  geom_boxplot(outlier.shape = NA) +  # Remove outlier points from the boxplot itself
  geom_jitter(aes(fill = ifelse(Gini_data > gini_cutoff, "red", "black")),
              shape = 21,
              position = position_jitter(width = 0.2, seed = 1)) +  # Jittered points with conditional fill color
  geom_hline(yintercept = gini_cutoff,
             linetype = "dotted",
             color = "red") +  # Add threshold line at 0.95
  ylim(min(QAQC_annotated$Gini_data, na.rm = TRUE) - 0.01, 1) +  # Dynamic lower limit, upper limit set to 1
  ylab("Gini Coefficient") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  scale_fill_identity() +  # Maintain fill colors
  ggtitle("Gini Coefficient by Treatment")

ggnmr <-
  ggplot(dplyr::filter(QAQC_annotated, is.na(Any) |
                         Any != "FAIL"),
         aes(x = !!ensym(treatment_var), y = NMR_data)) +
  geom_boxplot(outlier.shape = NA) +  # Remove outlier points from the boxplot itself
  geom_jitter(
    shape = 21,
    fill = "blue",
    position = position_jitter(width = 0.2, seed = 1)
  ) +  # Jittered points with consistent fill color
  geom_hline(yintercept = nmr_threshold,
             linetype = "dotted",
             color = "red") +  # Add threshold line at nmr_threshold
  ylim(0, max(QAQC_annotated$NMR_data, na.rm = TRUE) + 1000) +  # Dynamic y-axis from 0 to max value
  ylab("Number of Mapped Reads") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("Number of Total Mapped Reads by Treatment")

ggncov5 <-
  ggplot(dplyr::filter(QAQC_annotated, is.na(Any) |
                         Any != "FAIL"),
         aes(x = !!ensym(treatment_var), y = Ncov5_data)) +
  geom_boxplot(outlier.shape = NA) +  # Remove outlier points from the boxplot itself
  geom_jitter(
    shape = 21,
    fill = "blue",
    position = position_jitter(width = 0.2, seed = 1)
  ) +  # Jittered points with consistent fill color
  ylim(
    min(QAQC_annotated$Ncov5_data, na.rm = TRUE) - 0.01,
    max(QAQC_annotated$Ncov5_data, na.rm = TRUE) + 0.01
  ) +  # Dynamic y-axis from 0 to max value
  ylab("Proportion of Active Probes (>5 Mapped Reads)") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("NCov5")

ggnsig80 <-
  ggplot(dplyr::filter(QAQC_annotated, is.na(Any) |
                         Any != "FAIL"),
         aes(x = !!ensym(treatment_var), y = Nsig80_data)) +
  geom_boxplot(outlier.shape = NA) +  # Remove outlier points from the boxplot itself
  geom_jitter(
    shape = 21,
    fill = "blue",
    position = position_jitter(width = 0.2, seed = 100)
  ) +  # Jittered points with consistent fill color
  ylim(
    min(QAQC_annotated$Nsig80_data, na.rm = TRUE) - 100,
    max(QAQC_annotated$Nsig80_data, na.rm = TRUE) + 1
  ) +  # Dynamic y-axis from 0 to max value
  ylab("# of Probes for 80% Signal") +  # Y-axis label
  xlab(as.character(treatment_var)) +  # X-axis label
  theme_minimal() +  # Minimal theme
  ggtitle("NSig80")

ggsave(gggini, file = paste0(paths$output, "/Gini_plot.pdf"))
ggsave(ggnmr, file = paste0(paths$output, "/Mapped_reads_plot.pdf"))
ggsave(ggncov5, file = paste0(paths$output, "/NCov5_plot.pdf"))
ggsave(ggnsig80, file = paste0(paths$output, "/NSig80_plot.pdf"))
ggsave(ggq30, file = paste0(paths$output, "/Q30_plot.pdf"))
ggsave(ggq30diff, file = paste0(paths$output, "/Q30_diff_plot.pdf"))
ggsave(ggpctmapped, file = paste0(paths$output, "/Pct_mapped_plot.pdf"))
ggsave(ggpc1var, file = paste0(paths$output, "/PC1_variance_plot.pdf"))
```

### Q30 Scores

```{r plot_filtered_Q30, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggq30)
```

### Difference in Q30 scores between paired reads

```{r plot_filtered_Q30_diff, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggq30diff)
```

### Percentage of reads mapping

```{r plot_filtered_pct_mapping, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggpctmapped)
```

### Total number of reads mapping

```{r plot_filtered_NMR, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggnmr)
```

### PC1 variance

```{plot_filtered_NMR, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggpc1var)
```

### Ncov5

```{r plot_filtered_Ncov5, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggncov5)
```

### Nsig80

```{r plot_filtered_Nsig80, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(ggnsig80)
```

### Gini coefficient

```{r plot_filtered_Gini, fig.width = 11, fig.height = 10, out.height='100%', out.width='100%', eval=any(grepl("dose", colnames(QAQC_annotated), ignore.case = T))}
print(gggini)
```

## {-}

# References {-}

If these methods were used in your study, please cite the following papers as appropriate:  

---
nocite: '@*'
---

<div id="refs"></div>

# Session Info

## Date the report was generated.

```{r reproducibility1, echo = FALSE}
## Date the report was generated
Sys.time()
```

## Parameters Used

From the list elements in each params${variable} used to generate this report.

```{r paramsList, echo = FALSE}
df <- as.data.frame(unlist(params))
names(df) <- "Parameter Value"
knitr::kable(as.data.frame(df), format = "markdown")
```

## Wallclock time spent generating the report.

```{r reproducibility2, echo = FALSE}
## Processing time in seconds
totalTime <- diff(c(startTime, Sys.time()))
round(totalTime, digits = 3)
```

## `R` session information.

```{r reproducibility3, echo = FALSE}
## Session info
options(width = 120)
session_info()
```

## Pandoc version used: `r rmarkdown::pandoc_version()`.

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>